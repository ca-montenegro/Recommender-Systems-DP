{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NDbSFfjUMOj8"
   },
   "source": [
    "# Eindhoven University of Technology, Netherlands.\n",
    "## Mathematics & Computer Science\n",
    "## Data Science Master track\n",
    "## Recommender Systems\n",
    "Lecturer: Dr. Vlado Menkovski\n",
    "- Franziska Boenisch\n",
    "- Adriano Cardace \n",
    "- Camilo Montenegro Hernandez\n",
    "\n",
    "## Sequence Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7k9GlgNMMOkB"
   },
   "source": [
    "## Task 1.1: Document-level Sentiment Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1756IUpGMOkF"
   },
   "source": [
    "Build a Bidirectional Recurrent Neural Network (RNN) model for multi-class sentiment classification. Compare the performance with a Unidirectional RNN model. Your model (each) shall\n",
    "include:\n",
    "\n",
    "- RNN network that learns sentence representation from input sequences.\n",
    "- Fully connected network that predicts sentiment label, given the learnt state representation.\n",
    "\n",
    "\n",
    "Train the model by using data iterator and batch generator. Evaluate the trained model on\n",
    "the provided test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "13GNLSaWu7np"
   },
   "source": [
    "## Unidirectional RNN Model for document level sentiment classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fpOej5yKMOkO"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import codecs\n",
    "import operator\n",
    "import numpy as np\n",
    "import re\n",
    "from time import time\n",
    "import _pickle as cPickle\n",
    "import keras\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import pandas as pd\n",
    "import IPython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 189
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 40052,
     "status": "ok",
     "timestamp": 1559294339888,
     "user": {
      "displayName": "Camilo Montenegro",
      "photoUrl": "https://lh6.googleusercontent.com/-Jn6HIGOBkEI/AAAAAAAAAAI/AAAAAAAAAGE/KRzSedPdx_c/s64/photo.jpg",
      "userId": "11354035389149471417"
     },
     "user_tz": -120
    },
    "id": "4Ke-hpLsMWUJ",
    "outputId": "5af8a249-e185-4d74-e1a5-0d1784169c31"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VGFqfpaLQ1LC"
   },
   "source": [
    "\n",
    "# Preprocessing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nHLNHNcAQ5IZ"
   },
   "source": [
    "We don't need to include this part, I think reading direclty with Pickle should be ok but better ask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4dJ6V35FMOke"
   },
   "outputs": [],
   "source": [
    "#data_path = 'gdrive/My Drive/Colab Notebooks/2IMM10/assignment3/doc_level-sentiment/doc_level'\n",
    "data_path = 'gdrive/My Drive/doc_level-sentiment/doc_level'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "umEo-xtIMOkl"
   },
   "outputs": [],
   "source": [
    "# num_regex = re.compile('^[+-]?[0-9]+\\.?[0-9]*$')\n",
    "\n",
    "# def create_vocab(domain, data_path, maxlen=0, vocab_size=0):\n",
    "    \n",
    "#     print('Creating vocab ...')\n",
    "\n",
    "#     f = os.path.join(data_path,'%s_text.txt'%(domain))\n",
    "\n",
    "#     total_words, unique_words = 0, 0\n",
    "#     word_freqs = {}\n",
    "\n",
    "#     fin = codecs.open(f, 'r', 'utf-8')\n",
    "#     for line in fin:\n",
    "#         words = line.split()\n",
    "#         if maxlen > 0 and len(words) > maxlen:\n",
    "#             continue\n",
    "\n",
    "#         for w in words:\n",
    "#             if not bool(num_regex.match(w)):\n",
    "#                 try:\n",
    "#                     word_freqs[w] += 1\n",
    "#                 except KeyError:\n",
    "#                     unique_words += 1\n",
    "#                     word_freqs[w] = 1\n",
    "#                 total_words += 1\n",
    "\n",
    "#     print ('  %i total words, %i unique words' % (total_words, unique_words))\n",
    "#     sorted_word_freqs = sorted(word_freqs.items(), key=operator.itemgetter(1), reverse=True)\n",
    "\n",
    "#     vocab = {'<pad>':0, '<unk>':1, '<num>':2}\n",
    "#     index = len(vocab)\n",
    "#     for word, _ in sorted_word_freqs:\n",
    "#         vocab[word] = index\n",
    "#         index += 1\n",
    "#         if vocab_size > 0 and index > vocab_size + 2:\n",
    "#             break\n",
    "#     if vocab_size > 0:\n",
    "#         print (' keep the top %i words' % vocab_size)\n",
    "\n",
    "  \n",
    "#     return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NyOfFBblMOku"
   },
   "outputs": [],
   "source": [
    "# def create_data(vocab, text_path, label_path, domain, skip_top, skip_len, replace_non_vocab):\n",
    "    \n",
    "#     data = []\n",
    "#     label = [] # {pos: 0, neg: 1, neu: 2}\n",
    "    \n",
    "#     f = codecs.open(text_path, 'r', 'utf-8')\n",
    "#     f_l = codecs.open(label_path, 'r', 'utf-8')\n",
    "    \n",
    "#     num_hit, unk_hit, skip_top_hit, total = 0., 0., 0., 0.\n",
    "#     pos_count, neg_count, neu_count = 0, 0, 0\n",
    "#     max_len = 0\n",
    "\n",
    "#     for line, score in zip(f, f_l):\n",
    "#         word_indices = []\n",
    "#         words = line.split()\n",
    "#         if skip_len > 0 and len(words) > skip_len:\n",
    "#             continue\n",
    "\n",
    "#         score = float(score.strip())\n",
    "#         if score < 3:\n",
    "#             neg_count += 1\n",
    "#             label.append(1)\n",
    "#         elif score > 3:\n",
    "#             pos_count += 1\n",
    "#             label.append(0)\n",
    "#         else:\n",
    "#             neu_count += 1\n",
    "#             label.append(2)\n",
    "          \n",
    "#         for word in words:\n",
    "#             if bool(num_regex.match(word)):\n",
    "#                 word_indices.append(vocab['<num>'])\n",
    "#                 num_hit += 1\n",
    "#             elif word in vocab:\n",
    "#                 word_ind = vocab[word]\n",
    "#                 if skip_top > 0 and word_ind < skip_top + 3:\n",
    "#                     skip_top_hit += 1\n",
    "#                 else:\n",
    "#                     word_indices.append(word_ind)\n",
    "#             else:\n",
    "#                 if replace_non_vocab:\n",
    "#                     word_indices.append(vocab['<unk>'])\n",
    "#                 unk_hit += 1\n",
    "#             total += 1\n",
    "\n",
    "#         if len(word_indices) > max_len:\n",
    "#             max_len = len(word_indices)\n",
    "\n",
    "#         data.append(word_indices)\n",
    "\n",
    "#     f.close()\n",
    "#     f_l.close()\n",
    "\n",
    "#     print('  <num> hit rate: %.2f%%, <unk> hit rate: %.2f%%' % (100*num_hit/total, 100*unk_hit/total))\n",
    "\n",
    "#     print (domain)\n",
    "#     print( 'pos count: ', pos_count )\n",
    "#     print( 'neg count: ', neg_count )\n",
    "#     print( 'neu count: ', neu_count )\n",
    "\n",
    "#     return np.array(data), np.array(label), max_len\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gAeaqFckMOk2"
   },
   "outputs": [],
   "source": [
    "# def prepare_data(domain, data_path, vocab_size, skip_top=0, skip_len=0, replace_non_vocab=1):\n",
    "    \n",
    "#     print(domain)\n",
    "\n",
    "#     assert domain in ['amazon_electronics', 'yelp14']\n",
    "\n",
    "#     vocab = create_vocab(domain, data_path, skip_len, vocab_size)\n",
    "\n",
    "#     text_path = os.path.join(data_path,'%s_text.txt'%(domain))\n",
    "#     score_path = os.path.join(data_path,'%s_label.txt'%(domain))\n",
    "\n",
    "#     data, label, max_len = create_data(vocab, text_path, score_path, domain, skip_top, \\\n",
    "#                                        skip_len, replace_non_vocab)\n",
    "\n",
    "#     return vocab, data, label, max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Xvsy16fWMOk9"
   },
   "outputs": [],
   "source": [
    "# domain_name = 'amazon_electronics'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "90gM-v1nMOlI"
   },
   "outputs": [],
   "source": [
    "# vocab, data_list, label_list, overall_maxlen = prepare_data(domain_name, data_path, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jWmnIxqJMOlR"
   },
   "outputs": [],
   "source": [
    "def read_pickle(data_path, file_name):\n",
    "  \n",
    "  f = open(os.path.join(data_path, file_name), 'rb')\n",
    "  read_file = cPickle.load(f)\n",
    "  f.close()\n",
    "\n",
    "  return read_file\n",
    "\n",
    "def save_pickle(data_path, file_name, data):\n",
    "  \n",
    "  f = open(os.path.join(data_path, file_name), 'wb')\n",
    "  cPickle.dump(data, f)\n",
    "  print(\" file saved to: %s\"%(os.path.join(data_path, file_name)))\n",
    "  f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QAq0-krEMOlZ"
   },
   "outputs": [],
   "source": [
    "# idx_words = dict((v,k) for (k,v) in vocab.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YlRbO9QyMOli"
   },
   "outputs": [],
   "source": [
    "# save_pickle(data_path, 'words_idx.pkl', vocab)\n",
    "# save_pickle(data_path, 'idx_words.pkl', idx_words)\n",
    "# save_pickle(data_path, 'data.pkl', data_list)\n",
    "# save_pickle(data_path, 'label.pkl', label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3813,
     "status": "ok",
     "timestamp": 1559294358350,
     "user": {
      "displayName": "Camilo Montenegro",
      "photoUrl": "https://lh6.googleusercontent.com/-Jn6HIGOBkEI/AAAAAAAAAAI/AAAAAAAAAGE/KRzSedPdx_c/s64/photo.jpg",
      "userId": "11354035389149471417"
     },
     "user_tz": -120
    },
    "id": "-F6sqpJ9MOlt",
    "outputId": "7c9fa63c-84b2-4260-f866-e0d8d043a800"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000\n"
     ]
    }
   ],
   "source": [
    "words_idx = read_pickle(data_path, 'words_idx.pkl')\n",
    "words_idx_1 = words_idx\n",
    "idx_words = read_pickle(data_path, 'idx_words.pkl')\n",
    "data = read_pickle(data_path, 'data.pkl')\n",
    "label = read_pickle(data_path, 'label.pkl')\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C_vhM7oRMOl4"
   },
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gqoDBmJeMOl6"
   },
   "outputs": [],
   "source": [
    "rand_idx = np.arange(len(data))\n",
    "np.random.shuffle(rand_idx)\n",
    "\n",
    "data = data[rand_idx]\n",
    "label = to_categorical(label)[rand_idx]\n",
    "\n",
    "data_size = len(data)\n",
    "\n",
    "test_x = data[0:1000]\n",
    "test_y = label[0:1000]\n",
    "\n",
    "dev_x = data[1000:5000]\n",
    "dev_y = label[1000:5000]\n",
    "\n",
    "train_x = data[5000:int(data_size)]\n",
    "train_y = label[5000:int(data_size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "52pvhjwOMOmB"
   },
   "outputs": [],
   "source": [
    "maxlen = np.max([len(d) for d in dev_x])\n",
    "\n",
    "import operator\n",
    "words_idx = [x for (x, _) in sorted(words_idx.items(), key=operator.itemgetter(1))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "avT7kvjbMOmI"
   },
   "outputs": [],
   "source": [
    "train_x_ = sequence.pad_sequences(train_x, maxlen)\n",
    "dev_x_ = sequence.pad_sequences(dev_x, maxlen)\n",
    "test_x_ = sequence.pad_sequences(test_x, maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mITt1HkGMOmO"
   },
   "outputs": [],
   "source": [
    "train_x_ = np.array(train_x_)\n",
    "train_y = np.array(train_y)\n",
    "\n",
    "dev_x_ = np.array(dev_x_)\n",
    "dev_y = np.array(dev_y)\n",
    "\n",
    "test_x_ = np.array(test_x_)\n",
    "test_y = np.array(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bNA27-0WMOmU"
   },
   "outputs": [],
   "source": [
    "class Dataiterator():\n",
    "    '''\n",
    "      1) Iteration over minibatches using next(); call reset() between epochs to randomly shuffle the data\n",
    "      2) Access to the entire dataset using all()\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, X, y, seq_length=32, decoder_dim=300, batch_size=32):      \n",
    "        self.X = X \n",
    "        self.y = y \n",
    "        self.num_data = len(X) # total number of examples\n",
    "        self.batch_size = batch_size # batch size\n",
    "        self.reset() # initial: shuffling examples and set index to 0\n",
    "    \n",
    "    def __iter__(self): # iterates data\n",
    "        return self\n",
    "\n",
    "\n",
    "    def reset(self): # initials\n",
    "        self.idx = 0\n",
    "        self.order = np.random.permutation(self.num_data) # shuffling examples by providing randomized ids \n",
    "        \n",
    "    def __next__(self): # return model inputs - outputs per batch\n",
    "        X_ids = [] # hold ids per batch \n",
    "        while len(X_ids) < self.batch_size:\n",
    "            X_id = self.order[self.idx] # copy random id from initial shuffling\n",
    "            X_ids.append(X_id)\n",
    "            self.idx += 1 # \n",
    "            if self.idx >= self.num_data: # exception if all examples of data have been seen (iterated)\n",
    "                self.reset()\n",
    "                raise StopIteration()\n",
    "        batch_X = self.X[np.array(X_ids)] # X values (encoder input) per batch\n",
    "        batch_y = self.y[np.array(X_ids)] # y_in values (decoder input) per batch\n",
    "        return batch_X, batch_y\n",
    "\n",
    "          \n",
    "    def all(self): # return all data examples\n",
    "        return self.X, self.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e_y8rgmEMOmb"
   },
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Dropout, Activation, Embedding, LSTM, Input, Bidirectional\n",
    "from keras.models import Model\n",
    "import keras.optimizers as opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-hp8B8f4MOmg"
   },
   "outputs": [],
   "source": [
    "sentence_input = Input(shape=(None,), dtype='int32', name='sentence_input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rBK3fGPiMOml"
   },
   "outputs": [],
   "source": [
    "vocab_size = len(words_idx)\n",
    "word_emb = Embedding(vocab_size, 300, mask_zero=True, name='word_emb')\n",
    "emb_output = word_emb(sentence_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 759
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1571,
     "status": "ok",
     "timestamp": 1559316015473,
     "user": {
      "displayName": "Camilo Montenegro",
      "photoUrl": "https://lh6.googleusercontent.com/-Jn6HIGOBkEI/AAAAAAAAAAI/AAAAAAAAAGE/KRzSedPdx_c/s64/photo.jpg",
      "userId": "11354035389149471417"
     },
     "user_tz": -120
    },
    "id": "UUPPcrqQMOmq",
    "outputId": "a876c465-39cb-4697-c7b5-d932ef41db77"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "sentence_input (InputLayer)  (None, None)              0         \n",
      "_________________________________________________________________\n",
      "word_emb (Embedding)         (None, None, 300)         3000900   \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 300)               721200    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 3)                 903       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 3,723,003\n",
      "Trainable params: 3,723,003\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"337pt\" viewBox=\"0.00 0.00 181.00 337.00\" width=\"181pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 333)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"#ffffff\" points=\"-4,4 -4,-333 177,-333 177,4 -4,4\" stroke=\"transparent\"/>\n",
       "<!-- 140120524058296 -->\n",
       "<g class=\"node\" id=\"node1\">\n",
       "<title>140120524058296</title>\n",
       "<polygon fill=\"none\" points=\"0,-292.5 0,-328.5 173,-328.5 173,-292.5 0,-292.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"86.5\" y=\"-306.8\">sentence_input: InputLayer</text>\n",
       "</g>\n",
       "<!-- 140120533937008 -->\n",
       "<g class=\"node\" id=\"node2\">\n",
       "<title>140120533937008</title>\n",
       "<polygon fill=\"none\" points=\"9.5,-219.5 9.5,-255.5 163.5,-255.5 163.5,-219.5 9.5,-219.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"86.5\" y=\"-233.8\">word_emb: Embedding</text>\n",
       "</g>\n",
       "<!-- 140120524058296&#45;&gt;140120533937008 -->\n",
       "<g class=\"edge\" id=\"edge1\">\n",
       "<title>140120524058296-&gt;140120533937008</title>\n",
       "<path d=\"M86.5,-292.4551C86.5,-284.3828 86.5,-274.6764 86.5,-265.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"90.0001,-265.5903 86.5,-255.5904 83.0001,-265.5904 90.0001,-265.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140120523737688 -->\n",
       "<g class=\"node\" id=\"node3\">\n",
       "<title>140120523737688</title>\n",
       "<polygon fill=\"none\" points=\"43,-146.5 43,-182.5 130,-182.5 130,-146.5 43,-146.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"86.5\" y=\"-160.8\">lstm: LSTM</text>\n",
       "</g>\n",
       "<!-- 140120533937008&#45;&gt;140120523737688 -->\n",
       "<g class=\"edge\" id=\"edge2\">\n",
       "<title>140120533937008-&gt;140120523737688</title>\n",
       "<path d=\"M86.5,-219.4551C86.5,-211.3828 86.5,-201.6764 86.5,-192.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"90.0001,-192.5903 86.5,-182.5904 83.0001,-192.5904 90.0001,-192.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140120523737856 -->\n",
       "<g class=\"node\" id=\"node4\">\n",
       "<title>140120523737856</title>\n",
       "<polygon fill=\"none\" points=\"40.5,-73.5 40.5,-109.5 132.5,-109.5 132.5,-73.5 40.5,-73.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"86.5\" y=\"-87.8\">dense: Dense</text>\n",
       "</g>\n",
       "<!-- 140120523737688&#45;&gt;140120523737856 -->\n",
       "<g class=\"edge\" id=\"edge3\">\n",
       "<title>140120523737688-&gt;140120523737856</title>\n",
       "<path d=\"M86.5,-146.4551C86.5,-138.3828 86.5,-128.6764 86.5,-119.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"90.0001,-119.5903 86.5,-109.5904 83.0001,-119.5904 90.0001,-119.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140120523738416 -->\n",
       "<g class=\"node\" id=\"node5\">\n",
       "<title>140120523738416</title>\n",
       "<polygon fill=\"none\" points=\"9.5,-.5 9.5,-36.5 163.5,-36.5 163.5,-.5 9.5,-.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"86.5\" y=\"-14.8\">activation_4: Activation</text>\n",
       "</g>\n",
       "<!-- 140120523737856&#45;&gt;140120523738416 -->\n",
       "<g class=\"edge\" id=\"edge4\">\n",
       "<title>140120523737856-&gt;140120523738416</title>\n",
       "<path d=\"M86.5,-73.4551C86.5,-65.3828 86.5,-55.6764 86.5,-46.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"90.0001,-46.5903 86.5,-36.5904 83.0001,-46.5904 90.0001,-46.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 31,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dropout= 0.5\n",
    "recurrent_dropout = 0.1 \n",
    "lstm_layer = LSTM(300, return_sequences=False, dropout=dropout, recurrent_dropout=recurrent_dropout, name='lstm')(emb_output)\n",
    "densed = Dense(3, name='dense')(lstm_layer)\n",
    "probs = Activation('softmax')(densed)\n",
    "\n",
    "model = Model(inputs=[sentence_input], outputs=probs)\n",
    "\n",
    "optimizer = opt.RMSprop(lr=0.001, rho=0.9, epsilon=1e-06, clipnorm=10, clipvalue=0)\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "model.summary()\n",
    "IPython.display.SVG(keras.utils.vis_utils.model_to_dot(model).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ne0bCAbmMOmz"
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "train_steps_epoch = len(train_x_)/batch_size\n",
    "batch_train_iter = Dataiterator(train_x_, train_y, batch_size)\n",
    "val_steps_epoch = len(dev_x_)/batch_size\n",
    "batch_val_iter = Dataiterator(dev_x_, dev_y, batch_size)\n",
    "\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "def train_generator(model, batch_train_iter, batch_val_iter):\n",
    "    earlystop_callbacks = [EarlyStopping(monitor='val_loss', patience=10),\n",
    "                     ModelCheckpoint(filepath=os.path.join('./','{epoch:02d}-{loss:.2f}.check'), \\\n",
    "                                     monitor='val_loss', save_best_only=False, \\\n",
    "                                     save_weights_only=True)\n",
    "                     ]\n",
    "    \n",
    "    def train_gen():\n",
    "        while True:\n",
    "            train_batches = [[X, y] for X, y in batch_train_iter]\n",
    "            for train_batch in train_batches:\n",
    "                yield train_batch\n",
    "                \n",
    "    def val_gen():\n",
    "        while True:\n",
    "            val_batches = [[X, y] for X, y in batch_val_iter]\n",
    "            for val_batch in val_batches:\n",
    "                yield val_batch\n",
    "                \n",
    "    history = model.fit_generator(train_gen(), validation_data=val_gen(), \\\n",
    "                                  validation_steps=val_steps_epoch, steps_per_epoch=train_steps_epoch, \\\n",
    "                                  epochs = 1, callbacks = earlystop_callbacks)\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1020
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7886133,
     "status": "ok",
     "timestamp": 1558967161358,
     "user": {
      "displayName": "Camilo Montenegro",
      "photoUrl": "https://lh6.googleusercontent.com/-Jn6HIGOBkEI/AAAAAAAAAAI/AAAAAAAAAGE/KRzSedPdx_c/s64/photo.jpg",
      "userId": "11354035389149471417"
     },
     "user_tz": -120
    },
    "id": "gF_LhlFYMOm9",
    "outputId": "3883f040-e5d1-4f20-e2ad-7e258b9630de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1\n",
      "Epoch 1/1\n",
      "782/781 [==============================] - 1584s 2s/step - loss: 0.9184 - categorical_accuracy: 0.5572 - val_loss: 0.8204 - val_categorical_accuracy: 0.6375\n",
      "Iteration: 2\n",
      "Epoch 1/1\n",
      "782/781 [==============================] - 1631s 2s/step - loss: 0.7613 - categorical_accuracy: 0.6625 - val_loss: 0.7471 - val_categorical_accuracy: 0.6745\n",
      "Iteration: 3\n",
      "Epoch 1/1\n",
      "782/781 [==============================] - 1551s 2s/step - loss: 0.6921 - categorical_accuracy: 0.7000 - val_loss: 0.7471 - val_categorical_accuracy: 0.6707\n",
      "Iteration: 4\n",
      "Epoch 1/1\n",
      "782/781 [==============================] - 1524s 2s/step - loss: 0.6392 - categorical_accuracy: 0.7288 - val_loss: 0.7171 - val_categorical_accuracy: 0.6837\n",
      "Iteration: 5\n",
      "Epoch 1/1\n",
      "782/781 [==============================] - 1593s 2s/step - loss: 0.5886 - categorical_accuracy: 0.7546 - val_loss: 0.7188 - val_categorical_accuracy: 0.6800\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "  print('Iteration:',str(i+1))\n",
    "  train_generator(model, batch_train_iter, batch_val_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CBiOypoCMOnD"
   },
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AbpfSRmhf5Sj"
   },
   "outputs": [],
   "source": [
    "testPhrases = [\"i bought this book to understand about the technical thought process in the character mind but was disappointed to see that all that has been explained is about the stories behind those photographs but like the print quality of the book and the photographs\",'terrible terrible this is not a brand new product the box was already open and it looks like someone used it was totally open when i got that i have to return it','i did a bit of comparison shopping on amazon and decided on this computer it has lots of space and is fast enough for me i do not play games on this laptop so i dont know anything about graphics etc i feel i got a great laptop for the price and it suits my simple needs']\n",
    "testPhrases_array = []\n",
    "for phrase in testPhrases:\n",
    "  testPhrase_array = []\n",
    "  for word in phrase.split(' '):\n",
    "    idxWord = words_idx_1[word]\n",
    "    testPhrase_array.append(idxWord)\n",
    "  testPhrases_array.append(testPhrase_array)\n",
    "#print((testPhrases_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EC3WYYNMp38V"
   },
   "outputs": [],
   "source": [
    "predictions = []\n",
    "for phrase in testPhrases_array:\n",
    "  prediction = model.predict(np.expand_dims(phrase,0))  \n",
    "  predictions.append(np.argmax(prediction.flatten()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_YsQaQnfp7hm"
   },
   "outputs": [],
   "source": [
    "predictions = pd.DataFrame(predictions)\n",
    "testPhrases = pd.DataFrame(testPhrases)\n",
    "testPhrases['Predicted Label'] = (predictions)\n",
    "testPhrases.columns = ['Test review','Predicted Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 261
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 665,
     "status": "ok",
     "timestamp": 1558968340135,
     "user": {
      "displayName": "Camilo Montenegro",
      "photoUrl": "https://lh6.googleusercontent.com/-Jn6HIGOBkEI/AAAAAAAAAAI/AAAAAAAAAGE/KRzSedPdx_c/s64/photo.jpg",
      "userId": "11354035389149471417"
     },
     "user_tz": -120
    },
    "id": "OaU-sS0np8JM",
    "outputId": "cff890c2-ff8f-487d-e5cf-73ebab785b3b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: Positive. 1: Negative. 2: Neutral\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test review</th>\n",
       "      <th>Predicted Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i bought this book to understand about the technical thought process in the character mind but was disappointed to see that all that has been explained is about the stories behind those photographs but like the print quality of the book and the photographs</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>terrible terrible this is not a brand new product the box was already open and it looks like someone used it was totally open when i got that i have to return it</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i did a bit of comparison shopping on amazon and decided on this computer it has lots of space and is fast enough for me i do not play games on this laptop so i dont know anything about graphics etc i feel i got a great laptop for the price and it suits my simple needs</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                     Test review  Predicted Label\n",
       "0  i bought this book to understand about the technical thought process in the character mind but was disappointed to see that all that has been explained is about the stories behind those photographs but like the print quality of the book and the photographs               2              \n",
       "1  terrible terrible this is not a brand new product the box was already open and it looks like someone used it was totally open when i got that i have to return it                                                                                                              1              \n",
       "2  i did a bit of comparison shopping on amazon and decided on this computer it has lots of space and is fast enough for me i do not play games on this laptop so i dont know anything about graphics etc i feel i got a great laptop for the price and it suits my simple needs  0              "
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"0: Positive. 1: Negative. 2: Neutral\")\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "display(testPhrases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d4WG4_LseI66"
   },
   "source": [
    "As we can see from the example above, the first sentence is classified as neutral, since both the words 'disappointed' and 'like' appears. Also the second and the third sentences, that are clearly negative and positive correspondigly, have been classifed correctly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 55333,
     "status": "ok",
     "timestamp": 1558968056338,
     "user": {
      "displayName": "Camilo Montenegro",
      "photoUrl": "https://lh6.googleusercontent.com/-Jn6HIGOBkEI/AAAAAAAAAAI/AAAAAAAAAGE/KRzSedPdx_c/s64/photo.jpg",
      "userId": "11354035389149471417"
     },
     "user_tz": -120
    },
    "id": "G-wTFDxrPleH",
    "outputId": "41b107a5-a491-4224-a0b7-6e0e8bfdf03e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.706\n"
     ]
    }
   ],
   "source": [
    "steps = len(test_x)/batch_size\n",
    "\n",
    "batch_test_iter = Dataiterator(test_x, test_y, batch_size)\n",
    "\n",
    "def test_gen():\n",
    "  while True:\n",
    "    test_batches = [[X, y] for X, y in batch_test_iter]\n",
    "    for test_batch in test_batches:\n",
    "      print(test_batch)\n",
    "      #       yield test_batch\n",
    "                \n",
    "n = len(test_x)\n",
    "correct = 0\n",
    "for i, x in enumerate(test_x):   \n",
    "  if len(x)>0:\n",
    "    p = model.predict(np.expand_dims(np.array(test_x[i]), 0))\n",
    "    if np.argmax(p.flatten()) == np.argmax(test_y[i]):\n",
    "      correct +=1\n",
    "\n",
    "print(correct/n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "39bJwQH2fGaT"
   },
   "source": [
    "The accuracy for the test set is about 0.7. It is probably possible to achieve a better score by training with more epochs, but since it takes a lot of time we decided to stop after 5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dCiaOyXqMOnE"
   },
   "source": [
    "## Bidirectional RNN Model for document level sentiment classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 759
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1778,
     "status": "ok",
     "timestamp": 1559315999241,
     "user": {
      "displayName": "Camilo Montenegro",
      "photoUrl": "https://lh6.googleusercontent.com/-Jn6HIGOBkEI/AAAAAAAAAAI/AAAAAAAAAGE/KRzSedPdx_c/s64/photo.jpg",
      "userId": "11354035389149471417"
     },
     "user_tz": -120
    },
    "id": "XopHmtvaMOnF",
    "outputId": "a0fa8dcc-db57-4628-aae9-e3e003b415f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "sentence_input (InputLayer)  (None, None)              0         \n",
      "_________________________________________________________________\n",
      "word_emb (Embedding)         (None, None, 300)         3000900   \n",
      "_________________________________________________________________\n",
      "bidirectional_3 (Bidirection (None, 600)               1442400   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 3)                 1803      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 4,445,103\n",
      "Trainable params: 4,445,103\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"337pt\" viewBox=\"0.00 0.00 273.00 337.00\" width=\"273pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 333)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"#ffffff\" points=\"-4,4 -4,-333 269,-333 269,4 -4,4\" stroke=\"transparent\"/>\n",
       "<!-- 140120534006976 -->\n",
       "<g class=\"node\" id=\"node1\">\n",
       "<title>140120534006976</title>\n",
       "<polygon fill=\"none\" points=\"46,-292.5 46,-328.5 219,-328.5 219,-292.5 46,-292.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"132.5\" y=\"-306.8\">sentence_input: InputLayer</text>\n",
       "</g>\n",
       "<!-- 140120534007032 -->\n",
       "<g class=\"node\" id=\"node2\">\n",
       "<title>140120534007032</title>\n",
       "<polygon fill=\"none\" points=\"55.5,-219.5 55.5,-255.5 209.5,-255.5 209.5,-219.5 55.5,-219.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"132.5\" y=\"-233.8\">word_emb: Embedding</text>\n",
       "</g>\n",
       "<!-- 140120534006976&#45;&gt;140120534007032 -->\n",
       "<g class=\"edge\" id=\"edge1\">\n",
       "<title>140120534006976-&gt;140120534007032</title>\n",
       "<path d=\"M132.5,-292.4551C132.5,-284.3828 132.5,-274.6764 132.5,-265.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"136.0001,-265.5903 132.5,-255.5904 129.0001,-265.5904 136.0001,-265.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140120357120656 -->\n",
       "<g class=\"node\" id=\"node3\">\n",
       "<title>140120357120656</title>\n",
       "<polygon fill=\"none\" points=\"0,-146.5 0,-182.5 265,-182.5 265,-146.5 0,-146.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"132.5\" y=\"-160.8\">bidirectional_3(lstm): Bidirectional(LSTM)</text>\n",
       "</g>\n",
       "<!-- 140120534007032&#45;&gt;140120357120656 -->\n",
       "<g class=\"edge\" id=\"edge2\">\n",
       "<title>140120534007032-&gt;140120357120656</title>\n",
       "<path d=\"M132.5,-219.4551C132.5,-211.3828 132.5,-201.6764 132.5,-192.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"136.0001,-192.5903 132.5,-182.5904 129.0001,-192.5904 136.0001,-192.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140120534006920 -->\n",
       "<g class=\"node\" id=\"node4\">\n",
       "<title>140120534006920</title>\n",
       "<polygon fill=\"none\" points=\"86.5,-73.5 86.5,-109.5 178.5,-109.5 178.5,-73.5 86.5,-73.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"132.5\" y=\"-87.8\">dense: Dense</text>\n",
       "</g>\n",
       "<!-- 140120357120656&#45;&gt;140120534006920 -->\n",
       "<g class=\"edge\" id=\"edge3\">\n",
       "<title>140120357120656-&gt;140120534006920</title>\n",
       "<path d=\"M132.5,-146.4551C132.5,-138.3828 132.5,-128.6764 132.5,-119.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"136.0001,-119.5903 132.5,-109.5904 129.0001,-119.5904 136.0001,-119.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140120357207904 -->\n",
       "<g class=\"node\" id=\"node5\">\n",
       "<title>140120357207904</title>\n",
       "<polygon fill=\"none\" points=\"55.5,-.5 55.5,-36.5 209.5,-36.5 209.5,-.5 55.5,-.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"132.5\" y=\"-14.8\">activation_3: Activation</text>\n",
       "</g>\n",
       "<!-- 140120534006920&#45;&gt;140120357207904 -->\n",
       "<g class=\"edge\" id=\"edge4\">\n",
       "<title>140120534006920-&gt;140120357207904</title>\n",
       "<path d=\"M132.5,-73.4551C132.5,-65.3828 132.5,-55.6764 132.5,-46.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"136.0001,-46.5903 132.5,-36.5904 129.0001,-46.5904 136.0001,-46.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 28,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_input = Input(shape=(None,), dtype='int32', name='sentence_input')\n",
    "\n",
    "vocab_size = len(words_idx)\n",
    "word_emb = Embedding(vocab_size, 300, mask_zero=True, name='word_emb')\n",
    "emb_output = word_emb(sentence_input)\n",
    "\n",
    "dropout= 0.5\n",
    "recurrent_dropout = 0.1 \n",
    "lstm_layer = Bidirectional(LSTM(300, return_sequences=False, dropout=dropout,recurrent_dropout=recurrent_dropout, name='lstm'))(emb_output)\n",
    "densed = Dense(3, name='dense')(lstm_layer)\n",
    "probs = Activation('softmax')(densed)\n",
    "\n",
    "model = Model(inputs=[sentence_input], outputs=probs)\n",
    "\n",
    "optimizer = opt.RMSprop(lr=0.001, rho=0.9, epsilon=1e-06, clipnorm=10, clipvalue=0)\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "model.summary()\n",
    "\n",
    "IPython.display.SVG(keras.utils.vis_utils.model_to_dot(model).create(prog='dot', format='svg'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Iqe6v3pkMOnL"
   },
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1020
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 21277053,
     "status": "ok",
     "timestamp": 1559315693949,
     "user": {
      "displayName": "Camilo Montenegro",
      "photoUrl": "https://lh6.googleusercontent.com/-Jn6HIGOBkEI/AAAAAAAAAAI/AAAAAAAAAGE/KRzSedPdx_c/s64/photo.jpg",
      "userId": "11354035389149471417"
     },
     "user_tz": -120
    },
    "id": "7c3i-t5PMOnO",
    "outputId": "426ea819-3892-489d-a43c-af7ba32b9eb8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/1\n",
      "782/781 [==============================] - 4366s 6s/step - loss: 0.8743 - categorical_accuracy: 0.5868 - val_loss: 0.7670 - val_categorical_accuracy: 0.6470\n",
      "Iteration: 2\n",
      "Epoch 1/1\n",
      "782/781 [==============================] - 4419s 6s/step - loss: 0.7131 - categorical_accuracy: 0.6870 - val_loss: 0.7095 - val_categorical_accuracy: 0.6817\n",
      "Iteration: 3\n",
      "Epoch 1/1\n",
      "782/781 [==============================] - 4033s 5s/step - loss: 0.6349 - categorical_accuracy: 0.7296 - val_loss: 0.6930 - val_categorical_accuracy: 0.6817\n",
      "Iteration: 4\n",
      "Epoch 1/1\n",
      "782/781 [==============================] - 4306s 6s/step - loss: 0.5748 - categorical_accuracy: 0.7605 - val_loss: 0.7050 - val_categorical_accuracy: 0.6850\n",
      "Iteration: 5\n",
      "Epoch 1/1\n",
      "782/781 [==============================] - 4149s 5s/step - loss: 0.5184 - categorical_accuracy: 0.7893 - val_loss: 0.7744 - val_categorical_accuracy: 0.6777\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "  print('Iteration:',str(i+1))\n",
    "  train_generator(model, batch_train_iter, batch_val_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KSOYBRMzMOnX"
   },
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 8369464,
     "status": "ok",
     "timestamp": 1559315868965,
     "user": {
      "displayName": "Camilo Montenegro",
      "photoUrl": "https://lh6.googleusercontent.com/-Jn6HIGOBkEI/AAAAAAAAAAI/AAAAAAAAAGE/KRzSedPdx_c/s64/photo.jpg",
      "userId": "11354035389149471417"
     },
     "user_tz": -120
    },
    "id": "PMwcE9E1MOnY",
    "outputId": "5cba5292-f043-443e-a9b6-1767575e3fb0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy during evaluation: 0.665\n"
     ]
    }
   ],
   "source": [
    "steps = len(test_x)/batch_size\n",
    "\n",
    "batch_test_iter = Dataiterator(test_x, test_y, batch_size)\n",
    "\n",
    "def test_gen():\n",
    "  while True:\n",
    "    test_batches = [[X, y] for X, y in batch_test_iter]\n",
    "    for test_batch in test_batches:\n",
    "      print(test_batch)\n",
    "      #       yield test_batch\n",
    "                \n",
    "n = len(test_x)\n",
    "correct = 0\n",
    "for i, x in enumerate(test_x):   \n",
    "  if len(x)>0:\n",
    "    p = model.predict(np.expand_dims(np.array(test_x[i]), 0))\n",
    "    if np.argmax(p.flatten()) == np.argmax(test_y[i]):\n",
    "      correct +=1\n",
    "\n",
    "accu = correct/n\n",
    "print(\"Model accuracy during evaluation:\",str(accu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "02Oz2tPYYL2P"
   },
   "outputs": [],
   "source": [
    "testPhrases = [\"i bought this book to understand about the technical thought process in the character mind but was disappointed to see that all that has been explained is about the stories behind those photographs but like the print quality of the book and the photographs\",'terrible terrible this is not a brand new product the box was already open and it looks like someone used it was totally open when i got that i have to return it','i did a bit of comparison shopping on amazon and decided on this computer it has lots of space and is fast enough for me i do not play games on this laptop so i dont know anything about graphics etc i feel i got a great laptop for the price and it suits my simple needs','bought two both stopped working i do not recommend this mouse i bought one and one month later it stopped working for the price it wasnt worth returning so i just bought another one thinking i got a fluke bad one because i do like the light weight and feel but the second one stopped working after a few months i tried changing the battery with three different sets of batteries in case my batteries were bad i tried it on my desktop and my laptop it just stopped working']\n",
    "testPhrases_array = []\n",
    "for phrase in testPhrases:\n",
    "  testPhrase_array = []\n",
    "  for word in phrase.split(' '):\n",
    "    idxWord = words_idx_1[word]\n",
    "    testPhrase_array.append(idxWord)\n",
    "  testPhrases_array.append(testPhrase_array)\n",
    "#print((testPhrases_array))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-aWpFkO_qDlv"
   },
   "outputs": [],
   "source": [
    "predictions = []\n",
    "for phrase in testPhrases_array:\n",
    "  prediction = model.predict(np.expand_dims(phrase,0))  \n",
    "  predictions.append(np.argmax(prediction.flatten()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cSfhENChqEk2"
   },
   "outputs": [],
   "source": [
    "predictions = pd.DataFrame(predictions)\n",
    "testPhrases = pd.DataFrame(testPhrases)\n",
    "testPhrases['Predicted Label'] = (predictions)\n",
    "testPhrases.columns = ['Test review','Predicted Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 377
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 308,
     "status": "ok",
     "timestamp": 1559315934350,
     "user": {
      "displayName": "Camilo Montenegro",
      "photoUrl": "https://lh6.googleusercontent.com/-Jn6HIGOBkEI/AAAAAAAAAAI/AAAAAAAAAGE/KRzSedPdx_c/s64/photo.jpg",
      "userId": "11354035389149471417"
     },
     "user_tz": -120
    },
    "id": "GtcY2pekqGdD",
    "outputId": "3bdce454-c159-44e0-bb12-8bea4dca2fe9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence evaluation:\n",
      "0: Positive. 1: Negative. 2: Neutral\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test review</th>\n",
       "      <th>Predicted Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i bought this book to understand about the technical thought process in the character mind but was disappointed to see that all that has been explained is about the stories behind those photographs but like the print quality of the book and the photographs</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>terrible terrible this is not a brand new product the box was already open and it looks like someone used it was totally open when i got that i have to return it</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i did a bit of comparison shopping on amazon and decided on this computer it has lots of space and is fast enough for me i do not play games on this laptop so i dont know anything about graphics etc i feel i got a great laptop for the price and it suits my simple needs</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bought two both stopped working i do not recommend this mouse i bought one and one month later it stopped working for the price it wasnt worth returning so i just bought another one thinking i got a fluke bad one because i do like the light weight and feel but the second one stopped working after a few months i tried changing the battery with three different sets of batteries in case my batteries were bad i tried it on my desktop and my laptop it just stopped working</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                               Test review  Predicted Label\n",
       "0  i bought this book to understand about the technical thought process in the character mind but was disappointed to see that all that has been explained is about the stories behind those photographs but like the print quality of the book and the photographs                                                                                                                                                                                                                         0              \n",
       "1  terrible terrible this is not a brand new product the box was already open and it looks like someone used it was totally open when i got that i have to return it                                                                                                                                                                                                                                                                                                                        1              \n",
       "2  i did a bit of comparison shopping on amazon and decided on this computer it has lots of space and is fast enough for me i do not play games on this laptop so i dont know anything about graphics etc i feel i got a great laptop for the price and it suits my simple needs                                                                                                                                                                                                            2              \n",
       "3  bought two both stopped working i do not recommend this mouse i bought one and one month later it stopped working for the price it wasnt worth returning so i just bought another one thinking i got a fluke bad one because i do like the light weight and feel but the second one stopped working after a few months i tried changing the battery with three different sets of batteries in case my batteries were bad i tried it on my desktop and my laptop it just stopped working  1              "
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Sentence evaluation:\")\n",
    "print(\"0: Positive. 1: Negative. 2: Neutral\")\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "display(testPhrases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wyPXi7B_f9_T"
   },
   "source": [
    "With bidirectional RNN we get a better accuracy in training set, while we experience a worst accuracy in the test set (0.66 against the  0.70 that we got with unidirectional RNN ). This means that we are probably overfitting the data, since the Bidirectional RNNs are a more powerfull model this makes sense. Again we think that it would be possible to get an higher accuracy (for example using more dropout to reduce overfitting).    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mfVyIn8FhEWa"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Assignment-3.1.1.Document-Level-Sentiment.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
