{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uj4T8PEHGbMF"
   },
   "source": [
    "# Eindhoven University of Technology, Netherlands.\n",
    "## Mathematics & Computer Science\n",
    "## Data Science Master track\n",
    "## Recommender Systems\n",
    "Lecturer: Dr. Vlado Menkovski\n",
    "- Franziska Boenisch\n",
    "- Adriano Cardace \n",
    "- Camilo Montenegro Hernandez\n",
    "\n",
    "### Siamese networks & one-shot learning\n",
    "The Cifar-100 dataset is similar to the Cifar-10 dataset. It also consists of 60,000 32x32 RGB images, but they are distributed over 100 classes instead of 10. Thus, each class has much fewer examples, only 500 training images and 100 testing images per class. For more info about the dataset, see https://www.cs.toronto.edu/~kriz/cifar.html.\n",
    "\n",
    "*HINT: Import the Cifar-100 dataset directly from Keras, no need to download it from the website. Use* `label_mode=\"fine\"`\n",
    "\n",
    "### Task 1.1: Siamese network\n",
    "**a)**\n",
    "* Train a Siamese Network on the first 80 classes of (the training set of) Cifar-100, i.e. let the network predict the probability that two input images are from the same class. Use 1 as a target for pairs of images from the same class (positive pairs), and 0 for pairs of images from different classes (negative pairs). Randomly select image pairs from Cifar-100, but make sure you train on as many positive pairs as negative pairs.\n",
    "\n",
    "* Evaluate the performance of the network on 20-way one-shot learning tasks. Do this by generating 250 random tasks and obtain the average accuracy for each evaluation round. Use the remaining 20 classes that were not used for training. The model should perform better than random guessing.\n",
    "\n",
    "For this question you may ignore the test set of Cifar-100; it suffices to use only the training set and split this, using the first 80 classes for training and the remaining 20 classes for one-shot testing.\n",
    "\n",
    "*HINT: First sort the data by their labels (see e.g.* `numpy.argsort()`*), then reshape the data to a shape of* `(n_classes, n_examples, width, height, depth)`*, similar to the Omniglot data in Practical 4. It is then easier to split the data by class, and to sample positive and negative images pairs for training the Siamese network.*\n",
    "\n",
    "*NOTE: do not expect the one-shot accuracy for Cifar-100 to be similar to that accuracy for Omniglot; a lower accuracy can be expected. However, accuracy higher than random guess is certainly achievable.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "odVRSzmEp0uN",
    "outputId": "aae2bb3b-10c5-44ef-bd80-bd2c67a9b9a0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Conv2D, Lambda, Dense, Flatten, MaxPooling2D, Dropout, BatchNormalization, merge, concatenate, Activation\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.regularizers import l2\n",
    "from keras import backend as K\n",
    "from keras import optimizers\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.datasets import cifar100\n",
    "from keras.losses import binary_crossentropy\n",
    "from keras.utils import to_categorical\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "from itertools import permutations\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MaoAaEv17v6k"
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "from keras.datasets import cifar100\n",
    "\n",
    "# we are only interested in the train data\n",
    "(X, Y), (X_test, Y_test) = cifar100.load_data(label_mode=\"fine\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LphV5SWHnsrt"
   },
   "outputs": [],
   "source": [
    "def normalize(X_train,X_test):\n",
    "  #this function normalize inputs for zero mean and unit variance\n",
    "  # it is used when training a model.\n",
    "  # Input: training set and test set\n",
    "  # Output: normalized training set and test set according to the trianing set \n",
    "  #statistics.\n",
    "  mean = np.mean(X_train,axis=(0,1,2,3))\n",
    "  std = np.std(X_train, axis=(0, 1, 2, 3))\n",
    "  print('Set mean:',mean)\n",
    "  print('Set std:',std)\n",
    "  X_train = (X_train-mean)/(std+1e-7)\n",
    "  X_test = (X_test-mean)/(std+1e-7)\n",
    "  return X_train, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "colab_type": "code",
    "id": "TEkwJOny99Sg",
    "outputId": "47e22d71-9e46-4928-daf1-558f88f7b98f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set mean: 121.936059453125\n",
      "Set std: 68.38895658894971\n",
      "Put the data in the following form: class, example, w, h, c\n",
      "Training set shape: (100, 500, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "X, X_test = normalize(X,X_test)\n",
    "print('Put the data in the following form: class, example, w, h, c')\n",
    "#put the data in the following form: class, example, w, h, c\n",
    "indexes = np.argsort(Y.flatten())\n",
    "sorted_data = []\n",
    "for i in indexes:\n",
    "  sorted_data.append(X[i])\n",
    "X = np.array(sorted_data)\n",
    "Y = np.array(sorted(Y.flatten()))\n",
    "x_list=[]\n",
    "for i in range(100):\n",
    "  image_class = []\n",
    "  for j in range(500):\n",
    "    image_class.append(X[i*500+j])\n",
    "  x_list.append(np.array(image_class))\n",
    "X_array = np.array(x_list)\n",
    "print('Training set shape:',X_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "xmdFJ6v399Xq",
    "outputId": "c7249db1-f87c-41e9-9e93-7f107c856f1c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split in training set and test in first 80 and later 20 categories, respectively\n",
      "Training set shape: (80, 500, 32, 32, 3)\n",
      "Test set shape: (20, 500, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "#split in training set and test\n",
    "print('Split in training set and test in first 80 and later 20 categories, '+\n",
    "      'respectively')\n",
    "X_val = X_array[-20:, :, :, :, :]\n",
    "X_train = X_array[:80, :, :, :, :]\n",
    "print('Training set shape:',X_train.shape)\n",
    "print('Test set shape:',X_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bHOv9cnK99dJ"
   },
   "outputs": [],
   "source": [
    "def get_batch(batch_size, X):\n",
    "    \"\"\"Create batch of n pairs, half same class, half different class\"\"\"\n",
    "    n_classes, n_examples, w, h, d = X.shape\n",
    "    # randomly sample several classes to use in the batch\n",
    "    categories = np.random.choice(n_classes, size=(batch_size,), replace=False)\n",
    "    # initialize 2 empty arrays for the input image batch\n",
    "    pairs = [np.zeros((batch_size, h, w, 3)) for i in range(2)]\n",
    "    # initialize vector for the targets, and make one half of it '1's, so 2nd \n",
    "    #half of batch has same class\n",
    "    targets = np.zeros((batch_size,))\n",
    "    targets[batch_size//2:] = 1\n",
    "    for i in range(batch_size):\n",
    "        category = categories[i]\n",
    "        idx_1 = np.random.randint(0, n_examples)\n",
    "        pairs[0][i, :, :, :] = X[category, idx_1].reshape(w, h, 3)\n",
    "        idx_2 = np.random.randint(0, n_examples)\n",
    "        # pick images of same class for 1st half, different for 2nd\n",
    "        if i >= batch_size // 2:\n",
    "            category_2 = category\n",
    "        else:\n",
    "            #add a random number to the category modulo n_classes to ensure 2nd \n",
    "            #image has different category\n",
    "            category_2 = (category + np.random.randint(1,n_classes)) % n_classes\n",
    "        pairs[1][i, :, :, :] = X[category_2,idx_2].reshape(w, h, 3)\n",
    "    return pairs, targets\n",
    "\n",
    "def batch_generator(batch_size, X):\n",
    "    \"\"\"a generator for batches, so model.fit_generator can be used. \"\"\"\n",
    "    while True:\n",
    "        pairs, targets = get_batch(batch_size, X)\n",
    "        yield (pairs, targets)\n",
    "\n",
    "def train(model, X_train, batch_size=64, steps_per_epoch=625, epochs=1):\n",
    "    model.fit_generator(batch_generator(batch_size, X_train), \n",
    "                        steps_per_epoch=steps_per_epoch, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1024
    },
    "colab_type": "code",
    "id": "fHB49veO-whC",
    "outputId": "f5b39c49-8e98-4b63-e10b-b4b291ae4f5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_21 (Conv2D)           (None, 28, 28, 64)        4864      \n",
      "_________________________________________________________________\n",
      "batch_normalization_21 (Batc (None, 28, 28, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 12, 12, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_22 (Batc (None, 12, 12, 128)       512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 12, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 6, 6, 256)         295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_23 (Batc (None, 6, 6, 256)         1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 6, 6, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_24 (Conv2D)           (None, 6, 6, 256)         590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_24 (Batc (None, 6, 6, 256)         1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 6, 6, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               1179776   \n",
      "=================================================================\n",
      "Total params: 2,146,560\n",
      "Trainable params: 2,145,152\n",
      "Non-trainable params: 1,408\n",
      "_________________________________________________________________\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_3 (Sequential)       (None, 128)          2146560     input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 128)          0           sequential_3[1][0]               \n",
      "                                                                 sequential_3[2][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 1)            129         lambda_1[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 2,146,689\n",
      "Trainable params: 2,145,281\n",
      "Non-trainable params: 1,408\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_shape = (32, 32, 3)\n",
    "left_input = Input(input_shape)\n",
    "right_input = Input(input_shape)\n",
    "\n",
    "# build convnet to use in each siamese 'leg'\n",
    "convnet = Sequential()\n",
    "\n",
    "convnet.add(Conv2D(64, (5,5), input_shape=input_shape, kernel_regularizer=l2(2e-4)))\n",
    "convnet.add(BatchNormalization())\n",
    "convnet.add(LeakyReLU(alpha=0.1))\n",
    "# convnet.add(Dropout(0.5))\n",
    "convnet.add(MaxPooling2D())\n",
    "\n",
    "convnet.add(Conv2D(128, (3,3), input_shape=input_shape, kernel_regularizer=l2(2e-4)))\n",
    "convnet.add(BatchNormalization())\n",
    "convnet.add(LeakyReLU(alpha=0.1))\n",
    "# convnet.add(Dropout(0.5))\n",
    "convnet.add(MaxPooling2D())\n",
    "\n",
    "convnet.add(Conv2D(256, (3,3), input_shape=input_shape, padding='SAME', kernel_regularizer=l2(2e-4)))\n",
    "convnet.add(BatchNormalization())\n",
    "convnet.add(LeakyReLU(alpha=0.1))\n",
    "\n",
    "convnet.add(Conv2D(256, (3,3), input_shape=input_shape, padding='SAME', kernel_regularizer=l2(2e-4)))\n",
    "convnet.add(BatchNormalization())\n",
    "convnet.add(LeakyReLU(alpha=0.1))\n",
    "# convnet.add(Dropout(0.5))\n",
    "\n",
    "convnet.add(Flatten())\n",
    "\n",
    "convnet.add(Dense(128, activation=\"sigmoid\", kernel_regularizer=l2(1e-3)))\n",
    "convnet.summary()\n",
    "\n",
    "# encode each of the two inputs into a vector with the convnet\n",
    "encoded_l = convnet(left_input)\n",
    "encoded_r = convnet(right_input)\n",
    "\n",
    "# merge two encoded inputs with the L1 distance between them, and connect \n",
    "#to prediction output layer\n",
    "L1_distance = lambda x: K.abs(x[0]-x[1])\n",
    "both = Lambda(L1_distance)([encoded_l, encoded_r])\n",
    "prediction = Dense(1, activation='sigmoid')(both)\n",
    "siamese_net = Model(inputs=[left_input,right_input], outputs=prediction)\n",
    "\n",
    "\n",
    "optimizer = optimizers.Adam(lr=0.00001)\n",
    "siamese_net.compile(loss=\"binary_crossentropy\", optimizer=optimizer)\n",
    "\n",
    "\n",
    "siamese_net.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RkbXZnLaffah"
   },
   "outputs": [],
   "source": [
    "# show model\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "SVG(model_to_dot(siamese_net, show_shapes=True, show_layer_names=False, \n",
    "                 rankdir='TB').create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qU7rNa157v6r"
   },
   "outputs": [],
   "source": [
    "def make_oneshot_task(N, X):\n",
    "    \"\"\"Create pairs of (test image, support set image) with ground truth, for \n",
    "    testing N-way one-shot learning.\"\"\"\n",
    "    n_classes, n_examples, w, h, d = X.shape\n",
    "    indices = np.random.randint(0, n_examples, size=(N,))\n",
    "    \n",
    "    categories = np.random.choice(range(n_classes), size=(N,), replace=False) \n",
    "    \n",
    "    true_category = categories[0]\n",
    "    ex1, ex2 = np.random.choice(n_examples, replace=False, size=(2,))\n",
    "    test_image = np.asarray([X[true_category, ex1, :, :, :]]*N).reshape(N, w, h, 3)\n",
    "    support_set = X[categories, indices, :, :, :]\n",
    "    support_set[0, :, :, :] = X[true_category, ex2]\n",
    "    support_set = support_set.reshape(N, w, h, 3)\n",
    "    targets = np.zeros((N,))\n",
    "    targets[0] = 1\n",
    "    targets, test_image, support_set = shuffle(targets, test_image, support_set)\n",
    "    pairs = [test_image, support_set]\n",
    "    return pairs, targets\n",
    "\n",
    "def test_oneshot(model, X, N=20, k=250, verbose=True):\n",
    "    \"\"\"Test average N-way oneshot learning accuracy of a siamese neural net over\n",
    "    k one-shot tasks.\"\"\"\n",
    "    n_correct = 0\n",
    "    if verbose:\n",
    "        print(\"Evaluating model on {} random {}-way one-shot \" \n",
    "              \"learning tasks ...\".format(k, N))\n",
    "    for i in range(k):\n",
    "        inputs, targets = make_oneshot_task(N, X)\n",
    "        probs = model.predict(inputs)\n",
    "        if np.argmax(probs) == np.argmax(targets):\n",
    "            n_correct += 1\n",
    "    percent_correct = (100.0*n_correct / k)\n",
    "    if verbose:\n",
    "        print(\"Got an average of {}% accuracy for {}-way one-shot learning\"\n",
    "              .format(percent_correct, N))\n",
    "    return percent_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 8978
    },
    "colab_type": "code",
    "id": "pga3FGsrABOw",
    "outputId": "9fabb5bf-52b2-487f-f4bd-d53b28754cbd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Training loop 1 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 20s 31ms/step - loss: 1.0237\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 8.8% accuracy for 20-way one-shot learning\n",
      "********* New best one-shot accuracy, saving model ********\n",
      "=== Training loop 2 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 16s 26ms/step - loss: 0.9926\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 8.8% accuracy for 20-way one-shot learning\n",
      "********* New best one-shot accuracy, saving model ********\n",
      "=== Training loop 3 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 16s 26ms/step - loss: 0.9701\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 9.6% accuracy for 20-way one-shot learning\n",
      "********* New best one-shot accuracy, saving model ********\n",
      "=== Training loop 4 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 16s 25ms/step - loss: 0.9553\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 12.8% accuracy for 20-way one-shot learning\n",
      "********* New best one-shot accuracy, saving model ********\n",
      "=== Training loop 5 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 16s 26ms/step - loss: 0.9401\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 13.2% accuracy for 20-way one-shot learning\n",
      "********* New best one-shot accuracy, saving model ********\n",
      "=== Training loop 6 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 16s 26ms/step - loss: 0.9263\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 10.8% accuracy for 20-way one-shot learning\n",
      "=== Training loop 7 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 16s 26ms/step - loss: 0.9148\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 12.0% accuracy for 20-way one-shot learning\n",
      "=== Training loop 8 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 16s 26ms/step - loss: 0.9079\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 12.4% accuracy for 20-way one-shot learning\n",
      "=== Training loop 9 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 17s 26ms/step - loss: 0.8964\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 12.0% accuracy for 20-way one-shot learning\n",
      "=== Training loop 10 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 16s 26ms/step - loss: 0.8850\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 13.2% accuracy for 20-way one-shot learning\n",
      "********* New best one-shot accuracy, saving model ********\n",
      "=== Training loop 11 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 16s 26ms/step - loss: 0.8757\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 13.6% accuracy for 20-way one-shot learning\n",
      "********* New best one-shot accuracy, saving model ********\n",
      "=== Training loop 12 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 16s 26ms/step - loss: 0.8687\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 14.4% accuracy for 20-way one-shot learning\n",
      "********* New best one-shot accuracy, saving model ********\n",
      "=== Training loop 13 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 16s 26ms/step - loss: 0.8611\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 12.4% accuracy for 20-way one-shot learning\n",
      "=== Training loop 14 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 17s 27ms/step - loss: 0.8554\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 11.2% accuracy for 20-way one-shot learning\n",
      "=== Training loop 15 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 16s 26ms/step - loss: 0.8450\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 15.2% accuracy for 20-way one-shot learning\n",
      "********* New best one-shot accuracy, saving model ********\n",
      "=== Training loop 16 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 16s 26ms/step - loss: 0.8403\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 12.0% accuracy for 20-way one-shot learning\n",
      "=== Training loop 17 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 16s 26ms/step - loss: 0.8352\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 14.4% accuracy for 20-way one-shot learning\n",
      "=== Training loop 18 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 16s 26ms/step - loss: 0.8292\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 12.8% accuracy for 20-way one-shot learning\n",
      "=== Training loop 19 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 17s 26ms/step - loss: 0.8221\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 10.4% accuracy for 20-way one-shot learning\n",
      "=== Training loop 20 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 16s 26ms/step - loss: 0.8176\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 10.8% accuracy for 20-way one-shot learning\n",
      "=== Training loop 21 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 16s 26ms/step - loss: 0.8114\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 12.8% accuracy for 20-way one-shot learning\n",
      "=== Training loop 22 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 16s 26ms/step - loss: 0.8072\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 14.8% accuracy for 20-way one-shot learning\n",
      "=== Training loop 23 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 17s 27ms/step - loss: 0.8034\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 13.2% accuracy for 20-way one-shot learning\n",
      "=== Training loop 24 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 16s 26ms/step - loss: 0.7967\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 15.6% accuracy for 20-way one-shot learning\n",
      "********* New best one-shot accuracy, saving model ********\n",
      "=== Training loop 25 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 15s 25ms/step - loss: 0.7938\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 12.4% accuracy for 20-way one-shot learning\n",
      "=== Training loop 26 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 16s 26ms/step - loss: 0.7871\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 17.6% accuracy for 20-way one-shot learning\n",
      "********* New best one-shot accuracy, saving model ********\n",
      "=== Training loop 27 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 16s 26ms/step - loss: 0.7826\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 19.2% accuracy for 20-way one-shot learning\n",
      "********* New best one-shot accuracy, saving model ********\n",
      "=== Training loop 28 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 16s 25ms/step - loss: 0.7811\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 18.0% accuracy for 20-way one-shot learning\n",
      "=== Training loop 29 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 16s 25ms/step - loss: 0.7743\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 17.6% accuracy for 20-way one-shot learning\n",
      "=== Training loop 30 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 16s 26ms/step - loss: 0.7693\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 17.2% accuracy for 20-way one-shot learning\n",
      "=== Training loop 31 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 16s 26ms/step - loss: 0.7663\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 15.2% accuracy for 20-way one-shot learning\n",
      "=== Training loop 32 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 16s 26ms/step - loss: 0.7628\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 15.2% accuracy for 20-way one-shot learning\n",
      "=== Training loop 33 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 16s 26ms/step - loss: 0.7545\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 14.0% accuracy for 20-way one-shot learning\n",
      "=== Training loop 34 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 16s 26ms/step - loss: 0.7533\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 18.8% accuracy for 20-way one-shot learning\n",
      "=== Training loop 35 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 16s 26ms/step - loss: 0.7487\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 12.4% accuracy for 20-way one-shot learning\n",
      "=== Training loop 36 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 16s 26ms/step - loss: 0.7449\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 12.4% accuracy for 20-way one-shot learning\n",
      "=== Training loop 37 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 16s 26ms/step - loss: 0.7442\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 16.4% accuracy for 20-way one-shot learning\n",
      "=== Training loop 38 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 16s 26ms/step - loss: 0.7397\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 21.6% accuracy for 20-way one-shot learning\n",
      "********* New best one-shot accuracy, saving model ********\n",
      "=== Training loop 39 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 16s 25ms/step - loss: 0.7352\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 16.0% accuracy for 20-way one-shot learning\n",
      "=== Training loop 40 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 16s 26ms/step - loss: 0.7308\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 14.0% accuracy for 20-way one-shot learning\n",
      "=== Training loop 41 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 16s 26ms/step - loss: 0.7279\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 16.8% accuracy for 20-way one-shot learning\n",
      "=== Training loop 42 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 16s 26ms/step - loss: 0.7219\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 14.4% accuracy for 20-way one-shot learning\n",
      "=== Training loop 43 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 16s 25ms/step - loss: 0.7189\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 14.4% accuracy for 20-way one-shot learning\n",
      "=== Training loop 44 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 16s 26ms/step - loss: 0.7144\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 20.0% accuracy for 20-way one-shot learning\n",
      "=== Training loop 45 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 16s 26ms/step - loss: 0.7135\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 18.0% accuracy for 20-way one-shot learning\n",
      "=== Training loop 46 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 16s 25ms/step - loss: 0.7128\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 12.8% accuracy for 20-way one-shot learning\n",
      "=== Training loop 47 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 16s 26ms/step - loss: 0.7065\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 19.6% accuracy for 20-way one-shot learning\n",
      "=== Training loop 48 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 16s 26ms/step - loss: 0.7040\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 17.2% accuracy for 20-way one-shot learning\n",
      "=== Training loop 49 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 16s 26ms/step - loss: 0.7021\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 20.0% accuracy for 20-way one-shot learning\n",
      "=== Training loop 50 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 17s 27ms/step - loss: 0.6974\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 15.6% accuracy for 20-way one-shot learning\n",
      "=== Training loop 51 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 17s 26ms/step - loss: 0.6965\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 17.2% accuracy for 20-way one-shot learning\n",
      "=== Training loop 52 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 16s 26ms/step - loss: 0.6898\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 25.2% accuracy for 20-way one-shot learning\n",
      "********* New best one-shot accuracy, saving model ********\n",
      "=== Training loop 53 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 16s 25ms/step - loss: 0.6857\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 16.8% accuracy for 20-way one-shot learning\n",
      "=== Training loop 54 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 16s 26ms/step - loss: 0.6862\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 15.6% accuracy for 20-way one-shot learning\n",
      "=== Training loop 55 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 16s 26ms/step - loss: 0.6849\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 19.2% accuracy for 20-way one-shot learning\n",
      "=== Training loop 56 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 16s 26ms/step - loss: 0.6811\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 18.0% accuracy for 20-way one-shot learning\n",
      "=== Training loop 57 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 16s 26ms/step - loss: 0.6755\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 18.8% accuracy for 20-way one-shot learning\n",
      "=== Training loop 58 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 16s 26ms/step - loss: 0.6762\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 20.8% accuracy for 20-way one-shot learning\n",
      "=== Training loop 59 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 16s 26ms/step - loss: 0.6696\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 18.4% accuracy for 20-way one-shot learning\n",
      "=== Training loop 60 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 16s 26ms/step - loss: 0.6716\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 17.6% accuracy for 20-way one-shot learning\n",
      "=== Training loop 61 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 16s 26ms/step - loss: 0.6669\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 18.4% accuracy for 20-way one-shot learning\n",
      "=== Training loop 62 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 16s 26ms/step - loss: 0.6644\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 18.0% accuracy for 20-way one-shot learning\n",
      "=== Training loop 63 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 16s 25ms/step - loss: 0.6568\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 21.2% accuracy for 20-way one-shot learning\n",
      "=== Training loop 64 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 16s 26ms/step - loss: 0.6571\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 19.6% accuracy for 20-way one-shot learning\n",
      "=== Training loop 65 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 16s 26ms/step - loss: 0.6571\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 20.8% accuracy for 20-way one-shot learning\n",
      "=== Training loop 66 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 16s 26ms/step - loss: 0.6547\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 19.2% accuracy for 20-way one-shot learning\n",
      "=== Training loop 67 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 16s 25ms/step - loss: 0.6524\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 18.8% accuracy for 20-way one-shot learning\n",
      "=== Training loop 68 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 17s 27ms/step - loss: 0.6486\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 25.6% accuracy for 20-way one-shot learning\n",
      "********* New best one-shot accuracy, saving model ********\n",
      "=== Training loop 69 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 16s 26ms/step - loss: 0.6476\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 26.4% accuracy for 20-way one-shot learning\n",
      "********* New best one-shot accuracy, saving model ********\n",
      "=== Training loop 70 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 16s 26ms/step - loss: 0.6401\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 12.4% accuracy for 20-way one-shot learning\n",
      "=== Training loop 71 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 16s 25ms/step - loss: 0.6369\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 16.8% accuracy for 20-way one-shot learning\n",
      "=== Training loop 72 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 16s 26ms/step - loss: 0.6387\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 16.0% accuracy for 20-way one-shot learning\n",
      "=== Training loop 73 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 16s 26ms/step - loss: 0.6381\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 16.8% accuracy for 20-way one-shot learning\n",
      "=== Training loop 74 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 16s 26ms/step - loss: 0.6324\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 19.6% accuracy for 20-way one-shot learning\n",
      "=== Training loop 75 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 16s 26ms/step - loss: 0.6298\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 19.6% accuracy for 20-way one-shot learning\n",
      "=== Training loop 76 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 16s 26ms/step - loss: 0.6293\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 20.0% accuracy for 20-way one-shot learning\n",
      "=== Training loop 77 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 16s 25ms/step - loss: 0.6263\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 19.6% accuracy for 20-way one-shot learning\n",
      "=== Training loop 78 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 16s 25ms/step - loss: 0.6215\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 21.6% accuracy for 20-way one-shot learning\n",
      "=== Training loop 79 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 16s 26ms/step - loss: 0.6226\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 22.0% accuracy for 20-way one-shot learning\n",
      "=== Training loop 80 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 16s 26ms/step - loss: 0.6183\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 20.0% accuracy for 20-way one-shot learning\n",
      "=== Training loop 81 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 16s 25ms/step - loss: 0.6183\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 18.4% accuracy for 20-way one-shot learning\n",
      "=== Training loop 82 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 16s 26ms/step - loss: 0.6149\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 20.8% accuracy for 20-way one-shot learning\n",
      "=== Training loop 83 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 16s 26ms/step - loss: 0.6090\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 18.0% accuracy for 20-way one-shot learning\n",
      "=== Training loop 84 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 16s 26ms/step - loss: 0.6092\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 24.0% accuracy for 20-way one-shot learning\n",
      "=== Training loop 85 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 16s 25ms/step - loss: 0.6062\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 21.6% accuracy for 20-way one-shot learning\n",
      "=== Training loop 86 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 17s 27ms/step - loss: 0.6049\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 16.4% accuracy for 20-way one-shot learning\n",
      "=== Training loop 87 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 16s 26ms/step - loss: 0.5999\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 19.2% accuracy for 20-way one-shot learning\n",
      "=== Training loop 88 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 16s 26ms/step - loss: 0.6009\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 19.2% accuracy for 20-way one-shot learning\n",
      "=== Training loop 89 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 16s 26ms/step - loss: 0.5939\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 21.2% accuracy for 20-way one-shot learning\n",
      "=== Training loop 90 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 16s 26ms/step - loss: 0.5965\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 22.8% accuracy for 20-way one-shot learning\n",
      "=== Training loop 91 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 16s 26ms/step - loss: 0.5979\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 24.4% accuracy for 20-way one-shot learning\n",
      "=== Training loop 92 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 16s 25ms/step - loss: 0.5877\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 24.4% accuracy for 20-way one-shot learning\n",
      "=== Training loop 93 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 16s 26ms/step - loss: 0.5892\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 21.6% accuracy for 20-way one-shot learning\n",
      "=== Training loop 94 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 16s 25ms/step - loss: 0.5835\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 21.2% accuracy for 20-way one-shot learning\n",
      "=== Training loop 95 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 16s 25ms/step - loss: 0.5883\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 18.8% accuracy for 20-way one-shot learning\n",
      "=== Training loop 96 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 16s 26ms/step - loss: 0.5798\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 16.0% accuracy for 20-way one-shot learning\n",
      "=== Training loop 97 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 16s 26ms/step - loss: 0.5780\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 20.4% accuracy for 20-way one-shot learning\n",
      "=== Training loop 98 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 16s 25ms/step - loss: 0.5804\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 18.8% accuracy for 20-way one-shot learning\n",
      "=== Training loop 99 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 16s 25ms/step - loss: 0.5728\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 21.2% accuracy for 20-way one-shot learning\n",
      "=== Training loop 100 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 16s 26ms/step - loss: 0.5717\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 17.6% accuracy for 20-way one-shot learning\n"
     ]
    }
   ],
   "source": [
    "loops = 100\n",
    "best_acc = 0\n",
    "for i in range(loops):\n",
    "    print(\"=== Training loop {} ===\".format(i+1))\n",
    "    train(siamese_net, X_train)\n",
    "    test_acc = test_oneshot(siamese_net, X_val)\n",
    "    if test_acc >= best_acc:\n",
    "        print(\"********* New best one-shot accuracy, saving model ********\")\n",
    "        siamese_net.save(os.path.join(\".\", \"siamese.h5\"))\n",
    "        best_acc = test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "6W5F663MvuoN",
    "outputId": "d803ce51-f7e7-4964-f25f-52584319646e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy obtained after 100 loops of 1 epoch each:\n",
      "26.4\n"
     ]
    }
   ],
   "source": [
    "print('Best accuracy obtained after',loops,'loops of 1 epoch each:')\n",
    "print(best_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sYoEIHJsiufx"
   },
   "source": [
    "As we have 20 remaining classes, the probability for random guessing would be 1/20 which is 5%. Since we achieve a better result (26.4%), we can say that the network has actually learned a meaningful embedding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "COiAqXWDAgCe"
   },
   "source": [
    "***\n",
    "\n",
    "**b)** Compare the performance of your Siamese network for Cifar-100 to the Siamese network from Practical 4 for Omniglot. Name three fundamental differences between the Cifar-100 and Omniglot datasets. How do these differences influence the difference in one-shot accuracy?\n",
    "\n",
    "**Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IIHkoQ0PBWuB"
   },
   "source": [
    "#### Performance difference\n",
    "The performance in the Omniglot are much higher (about 80%) compared to the one that we have for Cifar-100.\n",
    "\n",
    "#### 3 Fundamental differences between Cifar-100 and Omniglot\n",
    "1) Omniglot: 1623 different handwritten characters from 50 different alphabets, Cifar-100: 50000 images from 100 classes. Hence, we have more data available, but also more classes.\n",
    "\n",
    "2) Omniglot is black and white (1 channel) and Cifar-100 is colored (3 channels).\n",
    "\n",
    "3) The imagees in Omniglot are larger (105x105) and in Cifar-100 is (32x32).\n",
    "\n",
    "\n",
    "#### How do the differences affect the one-shot accuracy\n",
    "The differences lead to poorer results for the Cifar-100 dataset than in Omniglot. The worse results are explicable by the fact that the Cifar-100 dataset is more complex (3 channels instead of 1 and they are complex shapes not only characters). Furthermore, the number of classes is larger in Cifar-100."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VWpFF_5-Bf4B"
   },
   "source": [
    "***\n",
    "\n",
    "### Task 1.2: One-shot learning with neural codes\n",
    "**a)**\n",
    "* Train a CNN classifier on the first 80 classes of Cifar-100. Make sure it achieves at least 40% classification accuracy on those 80 classes (use the test set to validate this accuracy).\n",
    "* Then use neural codes from one of the later hidden layers of the CNN with L2-distance to evaluate one-shot learning accuracy for the remaining 20 classes of Cifar-100 with 250 random tasks. I.e. for a given one-shot task, obtain neural codes for the test image as well as the support set. Then pick the image from the support set that is closest (in L2-distance) to the test image as your one-shot prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2hZ4tLJw2JuM"
   },
   "outputs": [],
   "source": [
    "(X, Y), (X_test, Y_test) = cifar100.load_data(label_mode=\"fine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "omHMzu3r2O_I",
    "outputId": "b77c4977-55f1-433c-bd99-85a1ccb17c6b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set mean: 121.93584\n",
      "Set std: 68.38902\n"
     ]
    }
   ],
   "source": [
    "X = X.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X, X_test = normalize(X, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zPYKHaIPhTer"
   },
   "outputs": [],
   "source": [
    "#select first 80 classes\n",
    "Y = Y.flatten()\n",
    "indexes = Y<80\n",
    "Y_test = Y_test.flatten()\n",
    "indexes1 = Y_test<80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "colab_type": "code",
    "id": "IzmfhWjxhWHA",
    "outputId": "95fdff95-0c3b-4658-b5b1-30311e363a67"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X-Training set shape: (40000, 32, 32, 3)\n",
      "Y-Training set shape: (40000,)\n",
      "Min class: 0 Max class: 79\n",
      "X-Test set shape: (8000, 32, 32, 3)\n",
      "Y-Test set shape: (8000,)\n",
      "Min class: 0 Max class: 79\n"
     ]
    }
   ],
   "source": [
    "X_train = X[indexes]\n",
    "Y_train = Y[indexes]\n",
    "print('X-Training set shape:',X_train.shape)\n",
    "print('Y-Training set shape:',Y_train.shape)\n",
    "print('Min class:',Y_train.min(),'Max class:', Y_train.max())\n",
    "X_test = X_test[indexes1]\n",
    "Y_test = Y_test[indexes1]\n",
    "print('X-Test set shape:',X_test.shape)\n",
    "print('Y-Test set shape:',Y_test.shape)\n",
    "print('Min class:',Y_test.min(),'Max class:', Y_test.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1320
    },
    "colab_type": "code",
    "id": "cd1QTgnZliSL",
    "outputId": "d437c492-9ae3-43a8-c586-0d8cb64dec17"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_35 (Conv2D)           (None, 26, 26, 64)        9472      \n",
      "_________________________________________________________________\n",
      "batch_normalization_35 (Batc (None, 26, 26, 64)        256       \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 26, 26, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_36 (Conv2D)           (None, 22, 22, 64)        102464    \n",
      "_________________________________________________________________\n",
      "batch_normalization_36 (Batc (None, 22, 22, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_37 (Conv2D)           (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_37 (Batc (None, 9, 9, 128)         512       \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 9, 9, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_38 (Conv2D)           (None, 7, 7, 128)         147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_38 (Batc (None, 7, 7, 128)         512       \n",
      "_________________________________________________________________\n",
      "conv2d_39 (Conv2D)           (None, 7, 7, 256)         295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_39 (Batc (None, 7, 7, 256)         1024      \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 7, 7, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_40 (Conv2D)           (None, 5, 5, 256)         590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_40 (Batc (None, 5, 5, 256)         1024      \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 5, 5, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_41 (Conv2D)           (None, 5, 5, 256)         590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_41 (Batc (None, 5, 5, 256)         1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_42 (Conv2D)           (None, 2, 2, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "batch_normalization_42 (Batc (None, 2, 2, 512)         2048      \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_43 (Conv2D)           (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_43 (Batc (None, 2, 2, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv2d_44 (Conv2D)           (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 2048)              4196352   \n",
      "_________________________________________________________________\n",
      "batch_normalization_44 (Batc (None, 2048)              8192      \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 128)               262272    \n",
      "_________________________________________________________________\n",
      "batch_normalization_45 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dropout_25 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "80Classes (Dense)            (None, 80)                10320     \n",
      "=================================================================\n",
      "Total params: 12,194,832\n",
      "Trainable params: 12,186,128\n",
      "Non-trainable params: 8,704\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_shape = (32, 32, 3)\n",
    "\n",
    "weight_decay = 0.0005\n",
    "\n",
    "convnet = Sequential()\n",
    "\n",
    "convnet.add(Conv2D(64, (7,7), activation='relu', input_shape=input_shape, \n",
    "                   kernel_regularizer=l2(2e-4)))\n",
    "#convnet.add(MaxPooling2D())\n",
    "convnet.add(BatchNormalization())\n",
    "convnet.add(Dropout(0.3))\n",
    "\n",
    "convnet.add(Conv2D(64, (5,5), activation='relu', input_shape=input_shape, \n",
    "                   kernel_regularizer=l2(2e-4)))\n",
    "convnet.add(BatchNormalization())\n",
    "convnet.add(MaxPooling2D())\n",
    "#convnet.add(Dropout(0.25))\n",
    "\n",
    "convnet.add(Conv2D(128, (3,3), activation='relu', input_shape=input_shape, \n",
    "                   kernel_regularizer=l2(2e-4)))\n",
    "#convnet.add(MaxPooling2D())\n",
    "convnet.add(BatchNormalization())\n",
    "convnet.add(Dropout(0.4))\n",
    "\n",
    "convnet.add(Conv2D(128, (3,3), activation='relu', kernel_regularizer=l2(2e-4)))\n",
    "convnet.add(BatchNormalization())\n",
    "#convnet.add(MaxPooling2D())\n",
    "#convnet.add(Dropout(0.25))\n",
    "\n",
    "convnet.add(Conv2D(256, (3,3), activation='relu', kernel_regularizer=l2(2e-4), \n",
    "                   padding='same'))\n",
    "convnet.add(BatchNormalization())\n",
    "convnet.add(Dropout(0.4))\n",
    "\n",
    "convnet.add(Conv2D(256, (3,3), activation='relu', kernel_regularizer=l2(2e-4)))\n",
    "convnet.add(BatchNormalization())\n",
    "convnet.add(Dropout(0.4))\n",
    "\n",
    "convnet.add(Conv2D(256, (3,3), activation='relu', kernel_regularizer=l2(2e-4), \n",
    "                   padding='same'))\n",
    "convnet.add(BatchNormalization())\n",
    "convnet.add(MaxPooling2D())\n",
    "\n",
    "convnet.add(Conv2D(512, (3,3), activation='relu', kernel_regularizer=l2(2e-4), \n",
    "                   padding='same'))\n",
    "convnet.add(BatchNormalization())\n",
    "convnet.add(Dropout(0.4))\n",
    "\n",
    "convnet.add(Conv2D(512, (3,3), activation='relu', kernel_regularizer=l2(2e-4), \n",
    "                   padding='same'))\n",
    "convnet.add(BatchNormalization())\n",
    "\n",
    "\n",
    "convnet.add(Conv2D(512, (3,3), activation='relu', kernel_regularizer=l2(2e-4), \n",
    "                   padding='same'))\n",
    "convnet.add(Flatten())\n",
    "\n",
    "convnet.add(Dense(2048, activation=\"relu\", kernel_regularizer=l2(1e-3)))\n",
    "convnet.add(BatchNormalization())\n",
    "convnet.add(Dropout(0.25))\n",
    "\n",
    "convnet.add(Dense(128, activation=\"relu\", kernel_regularizer=l2(1e-3)))\n",
    "convnet.add(BatchNormalization())\n",
    "convnet.add(Dropout(0.25))\n",
    "#convnet.add(BatchNormalization())\n",
    "#convnet.add(Dropout(0.4))\n",
    "\n",
    "convnet.add(Dense(80, activation=\"softmax\", kernel_regularizer=l2(1e-3),\n",
    "                  name='80Classes'))\n",
    "\n",
    "convnet.summary()\n",
    "\n",
    "\n",
    "\n",
    "optimizer = optimizers.Adam(lr=0.0001)\n",
    "# optimizer= optimizers.Adadelta(lr=1.0, rho=0.95, epsilon=None, decay=0.0)\n",
    "convnet.compile(loss=\"categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nsRtc-3xf7RY"
   },
   "outputs": [],
   "source": [
    "# show model\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "SVG(model_to_dot(convnet, show_shapes=True, show_layer_names=False, \n",
    "                 rankdir='TB').create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "vbz58qZfoKef",
    "outputId": "e911b1d4-4d4c-495d-e033-5780ba6a2e8b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One hot vectors for the labels: (40000, 80)\n"
     ]
    }
   ],
   "source": [
    "y_categorical = to_categorical(Y_train, 80)\n",
    "y_categorical_test = to_categorical(Y_test, 80)\n",
    "print('One hot vectors for the labels:',y_categorical.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NaiaPG_moqET"
   },
   "outputs": [],
   "source": [
    "#data augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "            featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "            samplewise_center=False,  # set each sample mean to 0\n",
    "            # divide inputs by std of the dataset\n",
    "            featurewise_std_normalization=False,  \n",
    "            samplewise_std_normalization=False,  # divide each input by its std\n",
    "            zca_whitening=False,  # apply ZCA whitening\n",
    "            # randomly rotate images in the range (degrees, 0 to 180)\n",
    "            rotation_range=15,  \n",
    "            # randomly shift images horizontally (fraction of total width)\n",
    "            width_shift_range=0.1,  \n",
    "            # randomly shift images vertically (fraction of total height)\n",
    "            height_shift_range=0.1,  \n",
    "            horizontal_flip=True,  # randomly flip images\n",
    "            vertical_flip=False)  # randomly flip images\n",
    "        # (std, mean, and principal components if ZCA whitening is applied).\n",
    "datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1771
    },
    "colab_type": "code",
    "id": "oztTyw3uDnbM",
    "outputId": "785febb2-10d0-47d9-df65-a3f0a4ec21ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "400/400 [==============================] - 33s 83ms/step - loss: 7.3650 - acc: 0.0350 - val_loss: 7.4935 - val_acc: 0.0395\n",
      "Epoch 2/50\n",
      "400/400 [==============================] - 25s 62ms/step - loss: 6.7531 - acc: 0.0689 - val_loss: 6.9806 - val_acc: 0.0550\n",
      "Epoch 3/50\n",
      "400/400 [==============================] - 25s 62ms/step - loss: 6.3879 - acc: 0.0973 - val_loss: 6.3876 - val_acc: 0.0746\n",
      "Epoch 4/50\n",
      "400/400 [==============================] - 27s 67ms/step - loss: 6.0494 - acc: 0.1170 - val_loss: 6.0996 - val_acc: 0.0875\n",
      "Epoch 5/50\n",
      "400/400 [==============================] - 25s 63ms/step - loss: 5.7354 - acc: 0.1312 - val_loss: 5.8167 - val_acc: 0.1071\n",
      "Epoch 6/50\n",
      "400/400 [==============================] - 25s 63ms/step - loss: 5.4337 - acc: 0.1507 - val_loss: 5.4625 - val_acc: 0.1275\n",
      "Epoch 7/50\n",
      "400/400 [==============================] - 26s 65ms/step - loss: 5.1540 - acc: 0.1661 - val_loss: 5.1178 - val_acc: 0.1576\n",
      "Epoch 8/50\n",
      "400/400 [==============================] - 25s 62ms/step - loss: 4.8911 - acc: 0.1818 - val_loss: 4.8390 - val_acc: 0.1814\n",
      "Epoch 9/50\n",
      "400/400 [==============================] - 25s 62ms/step - loss: 4.6590 - acc: 0.1967 - val_loss: 4.5567 - val_acc: 0.2059\n",
      "Epoch 10/50\n",
      "400/400 [==============================] - 26s 65ms/step - loss: 4.4527 - acc: 0.2111 - val_loss: 4.3428 - val_acc: 0.2221\n",
      "Epoch 11/50\n",
      "400/400 [==============================] - 25s 62ms/step - loss: 4.2585 - acc: 0.2284 - val_loss: 4.1383 - val_acc: 0.2482\n",
      "Epoch 12/50\n",
      "400/400 [==============================] - 25s 62ms/step - loss: 4.0920 - acc: 0.2431 - val_loss: 4.0079 - val_acc: 0.2601\n",
      "Epoch 13/50\n",
      "400/400 [==============================] - 25s 63ms/step - loss: 3.9576 - acc: 0.2563 - val_loss: 3.8617 - val_acc: 0.2709\n",
      "Epoch 14/50\n",
      "400/400 [==============================] - 26s 64ms/step - loss: 3.8423 - acc: 0.2672 - val_loss: 3.7799 - val_acc: 0.2820\n",
      "Epoch 15/50\n",
      "400/400 [==============================] - 25s 62ms/step - loss: 3.7209 - acc: 0.2797 - val_loss: 3.6029 - val_acc: 0.3038\n",
      "Epoch 16/50\n",
      "400/400 [==============================] - 25s 63ms/step - loss: 3.6165 - acc: 0.2928 - val_loss: 3.4682 - val_acc: 0.3214\n",
      "Epoch 17/50\n",
      "400/400 [==============================] - 26s 66ms/step - loss: 3.5273 - acc: 0.3023 - val_loss: 3.3922 - val_acc: 0.3326\n",
      "Epoch 18/50\n",
      "400/400 [==============================] - 25s 63ms/step - loss: 3.4464 - acc: 0.3128 - val_loss: 3.2746 - val_acc: 0.3408\n",
      "Epoch 19/50\n",
      "400/400 [==============================] - 25s 62ms/step - loss: 3.3774 - acc: 0.3212 - val_loss: 3.2775 - val_acc: 0.3420\n",
      "Epoch 20/50\n",
      "400/400 [==============================] - 26s 65ms/step - loss: 3.3127 - acc: 0.3284 - val_loss: 3.2055 - val_acc: 0.3548\n",
      "Epoch 21/50\n",
      "400/400 [==============================] - 25s 62ms/step - loss: 3.2432 - acc: 0.3386 - val_loss: 3.1736 - val_acc: 0.3521\n",
      "Epoch 22/50\n",
      "400/400 [==============================] - 25s 62ms/step - loss: 3.1868 - acc: 0.3491 - val_loss: 3.1016 - val_acc: 0.3615\n",
      "Epoch 23/50\n",
      "400/400 [==============================] - 26s 65ms/step - loss: 3.1352 - acc: 0.3565 - val_loss: 3.0057 - val_acc: 0.3844\n",
      "Epoch 24/50\n",
      "400/400 [==============================] - 25s 62ms/step - loss: 3.0900 - acc: 0.3628 - val_loss: 3.0318 - val_acc: 0.3761\n",
      "Epoch 25/50\n",
      "400/400 [==============================] - 25s 62ms/step - loss: 3.0378 - acc: 0.3727 - val_loss: 2.9720 - val_acc: 0.3865\n",
      "Epoch 26/50\n",
      "400/400 [==============================] - 26s 65ms/step - loss: 2.9939 - acc: 0.3778 - val_loss: 2.9124 - val_acc: 0.3970\n",
      "Epoch 27/50\n",
      "400/400 [==============================] - 25s 62ms/step - loss: 2.9513 - acc: 0.3846 - val_loss: 2.8725 - val_acc: 0.4061\n",
      "Epoch 28/50\n",
      "400/400 [==============================] - 25s 62ms/step - loss: 2.9162 - acc: 0.3928 - val_loss: 2.8858 - val_acc: 0.4016\n",
      "Epoch 29/50\n",
      "400/400 [==============================] - 27s 68ms/step - loss: 2.8828 - acc: 0.3979 - val_loss: 2.8828 - val_acc: 0.3968\n",
      "Epoch 30/50\n",
      "400/400 [==============================] - 25s 63ms/step - loss: 2.8392 - acc: 0.4067 - val_loss: 2.7732 - val_acc: 0.4206\n",
      "Epoch 31/50\n",
      "400/400 [==============================] - 25s 62ms/step - loss: 2.7948 - acc: 0.4134 - val_loss: 2.7517 - val_acc: 0.4256\n",
      "Epoch 32/50\n",
      "400/400 [==============================] - 25s 62ms/step - loss: 2.7688 - acc: 0.4158 - val_loss: 2.7540 - val_acc: 0.4305\n",
      "Epoch 33/50\n",
      "400/400 [==============================] - 26s 65ms/step - loss: 2.7384 - acc: 0.4260 - val_loss: 2.6982 - val_acc: 0.4366\n",
      "Epoch 34/50\n",
      "400/400 [==============================] - 25s 62ms/step - loss: 2.6979 - acc: 0.4327 - val_loss: 2.7022 - val_acc: 0.4346\n",
      "Epoch 35/50\n",
      "400/400 [==============================] - 25s 62ms/step - loss: 2.6751 - acc: 0.4373 - val_loss: 2.6908 - val_acc: 0.4392\n",
      "Epoch 36/50\n",
      "400/400 [==============================] - 26s 65ms/step - loss: 2.6471 - acc: 0.4398 - val_loss: 2.6123 - val_acc: 0.4525\n",
      "Epoch 37/50\n",
      "400/400 [==============================] - 25s 62ms/step - loss: 2.6242 - acc: 0.4470 - val_loss: 2.6448 - val_acc: 0.4512\n",
      "Epoch 38/50\n",
      "400/400 [==============================] - 25s 63ms/step - loss: 2.5859 - acc: 0.4535 - val_loss: 2.5872 - val_acc: 0.4572\n",
      "Epoch 39/50\n",
      "400/400 [==============================] - 26s 65ms/step - loss: 2.5655 - acc: 0.4607 - val_loss: 2.5905 - val_acc: 0.4549\n",
      "Epoch 40/50\n",
      "400/400 [==============================] - 25s 62ms/step - loss: 2.5491 - acc: 0.4613 - val_loss: 2.6659 - val_acc: 0.4496\n",
      "Epoch 41/50\n",
      "400/400 [==============================] - 26s 66ms/step - loss: 2.5116 - acc: 0.4682 - val_loss: 2.5466 - val_acc: 0.4677\n",
      "Epoch 42/50\n",
      "400/400 [==============================] - 27s 66ms/step - loss: 2.4933 - acc: 0.4744 - val_loss: 2.5655 - val_acc: 0.4631\n",
      "Epoch 43/50\n",
      "400/400 [==============================] - 25s 63ms/step - loss: 2.4643 - acc: 0.4766 - val_loss: 2.5876 - val_acc: 0.4591\n",
      "Epoch 44/50\n",
      "400/400 [==============================] - 25s 61ms/step - loss: 2.4472 - acc: 0.4831 - val_loss: 2.5129 - val_acc: 0.4731\n",
      "Epoch 45/50\n",
      "400/400 [==============================] - 26s 65ms/step - loss: 2.4366 - acc: 0.4850 - val_loss: 2.5359 - val_acc: 0.4699\n",
      "Epoch 46/50\n",
      "400/400 [==============================] - 25s 62ms/step - loss: 2.3959 - acc: 0.4947 - val_loss: 2.4940 - val_acc: 0.4807\n",
      "Epoch 47/50\n",
      "400/400 [==============================] - 25s 62ms/step - loss: 2.3952 - acc: 0.4980 - val_loss: 2.4784 - val_acc: 0.4851\n",
      "Epoch 48/50\n",
      "400/400 [==============================] - 25s 64ms/step - loss: 2.3668 - acc: 0.5019 - val_loss: 2.5107 - val_acc: 0.4832\n",
      "Epoch 49/50\n",
      "400/400 [==============================] - 25s 63ms/step - loss: 2.3355 - acc: 0.5099 - val_loss: 2.5337 - val_acc: 0.4754\n",
      "Epoch 50/50\n",
      "400/400 [==============================] - 25s 62ms/step - loss: 2.3182 - acc: 0.5164 - val_loss: 2.4919 - val_acc: 0.4869\n",
      "8000/8000 [==============================] - 2s 254us/step\n"
     ]
    }
   ],
   "source": [
    "batch_size = 100\n",
    "epochs = 50\n",
    "\n",
    "convnet.fit_generator(datagen.flow(X_train, y_categorical,\n",
    "                      batch_size=batch_size),\n",
    "                      epochs=epochs,\n",
    "                      steps_per_epoch=X_train.shape[0] // batch_size,\n",
    "                      validation_data=(X_test,y_categorical_test))\n",
    "\n",
    "score = convnet.evaluate(X_test,y_categorical_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "diy4_Jx1dLt4",
    "outputId": "2960b8c1-8d36-4e8f-9804-ae0a8ad87ef3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics obtained using the test set, first 80 classes of cifar 100 test set\n",
      "Loss value obtained after 50 epochs: 2.491881098270416\n",
      "Accuracy value obtained after 50 epochs: 48.6875%\n"
     ]
    }
   ],
   "source": [
    "print('Metrics obtained using the test set, first 80 classes of cifar 100 test set')\n",
    "print('Loss value obtained after {} epochs: {}'.format(epochs,score[0]))\n",
    "print('Accuracy value obtained after {} epochs: {}%'\n",
    "      .format(epochs,score[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "kygKZYdAuKL7",
    "outputId": "917b42f1-c7ee-490c-8320-4fcff90e3aef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set mean: 121.93584\n",
      "Set std: 68.38902\n",
      "Last 20 classes training set to evaluate neural codes: (20, 500, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "#take only the last 20 classes from the training set to evaluate neural codes \n",
    "#from CNN\n",
    "(X, Y), (X_test, Y_test) = cifar100.load_data(label_mode=\"fine\")\n",
    "X = X.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X, X_test = normalize(X, X_test)\n",
    "\n",
    "#put the data in the following form: class, example, w, h, c\n",
    "indexes = np.argsort(Y.flatten())\n",
    "sorted_data = []\n",
    "for i in indexes:\n",
    "  sorted_data.append(X[i])\n",
    "X = np.array(sorted_data)\n",
    "Y = np.array(sorted(Y.flatten()))\n",
    "x_list=[]\n",
    "for i in range(100):\n",
    "  image_class = []\n",
    "  for j in range(500):\n",
    "    image_class.append(X[i*500+j])\n",
    "  x_list.append(np.array(image_class))\n",
    "X_array = np.array(x_list)\n",
    "#print(X_array.shape)\n",
    "\n",
    "#class, example, w, h, c\n",
    "\n",
    "X_train = X_array[-20:, :, :, :, :]\n",
    "print('Last 20 classes training set to evaluate neural codes: '+\n",
    "      str(X_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5WBr7QtRhj3T"
   },
   "outputs": [],
   "source": [
    "def l2Distance(a,b):\n",
    "    return np.linalg.norm(a-b)\n",
    "\n",
    "def make_oneshot_task(N, X):\n",
    "    \"\"\"Create pairs of (test image, support set image) with ground truth, \n",
    "    for testing N-way one-shot learning.\"\"\"\n",
    "    n_classes, n_examples, w, h, d = X.shape\n",
    "    indices = np.random.randint(0, n_examples, size=(N,))\n",
    "    categories = np.random.choice(range(n_classes), size=(N,), replace=False)    \n",
    "    true_category = categories[0]\n",
    "    ex1, ex2 = np.random.choice(n_examples, replace=False, size=(2,))\n",
    "    test_image = np.asarray([X[true_category, ex1, :, :, :]]*N).reshape(N, w, h, 3)\n",
    "    support_set = X[categories, indices, :, :]\n",
    "    support_set[0, :, :, :] = X[true_category, ex2]\n",
    "    support_set = support_set.reshape(N, w, h, 3)\n",
    "    targets = np.zeros((N,))\n",
    "    targets[0] = 1\n",
    "    targets, test_image, support_set = shuffle(targets, test_image, support_set)\n",
    "    pairs = [test_image, support_set]\n",
    "    return pairs, targets\n",
    "\n",
    "def test_oneshot(model, X,  N=20, k=250, verbose=True):\n",
    "    \"\"\"Test average N-way oneshot learning accuracy of a siamese neural net \n",
    "    over k one-shot tasks.\"\"\"\n",
    "    n_correct = 0\n",
    "    if verbose:\n",
    "        print(\"Evaluating model on {} random {}-way one-shot learning tasks ...\"\n",
    "              .format(k, N))\n",
    "    for i in range(k):\n",
    "        pairs, label = make_oneshot_task(N, X)\n",
    "        #for each input pair, compute l2 distance between corresponding codes, \n",
    "        #if the index of the closest pair is equal to the target success\n",
    "        distances = []\n",
    "        for pair in pairs:\n",
    "          query_image=model.predict(np.expand_dims(pair[0], axis=0))\n",
    "#           print(query_image)\n",
    "          test_image=model.predict(np.expand_dims(pair[1], axis=0))\n",
    "#           print(test_image)\n",
    "          distances.append(l2Distance(query_image,test_image))\n",
    "          \n",
    "        if np.argmin(distances) == np.argmax(label):\n",
    "            n_correct += 1\n",
    "    percent_correct = (100.0*n_correct / k)\n",
    "    if verbose:\n",
    "        print(\"Got an average of {}% accuracy for {}-way one-shot learning\"\n",
    "              .format(percent_correct, N))\n",
    "    return percent_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "5s4mE5Udhlf_",
    "outputId": "71566050-b9da-4115-f195-f2b875d2cc04"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 6.4% accuracy for 20-way one-shot learning\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6.4"
      ]
     },
     "execution_count": 65,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc2_model = Model(inputs=convnet.input, outputs=convnet.get_layer(\"80Classes\")\n",
    "                  .output)\n",
    "\n",
    "test_oneshot(fc2_model, X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M1BDzdPAz26B"
   },
   "source": [
    "***\n",
    "\n",
    "**b)** Briefly motivate your CNN architecture, and discuss the difference in one-shot accuracy between the Siamese network approach and the CNN neural codes approach.\n",
    "\n",
    "**Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oRpVm956FR8P"
   },
   "source": [
    "The architecture is inspired by classical VGG network: blocks of convolutional layers, followed by a batch normalization layer to speed up the training, and a dropout layer to reduce overfitting. At the top of this convolutional layers, we stacked two dense layers: the former is needed to extract the codes, while the latter corresponds to a softmax layer used for the classification task.\n",
    "In order to improve the accuracy of the classification, and consequently the embedding, we also added data augmentation. Thanks to this trick, we are able to achieve about 50% of accuracy for the classification task.\n",
    "However, we can see that one-shot accuracy obtained with codes (6.4%), is still less than the one that we have using the Siamense network. This was probably predictable since the Siamense network is built specifically for learning embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p-gkaM1tCThc"
   },
   "source": [
    "***\n",
    "## Question 2: Triplet networks & one-shot learning (10pt)\n",
    "\n",
    "### Task 2.1: Train a triplet network\n",
    "**a)**\n",
    "* Train a triplet network on the first 80 classes of (the training set of) Cifar-100.\n",
    " \n",
    "* Make sure the network achieves a smaller loss than the margin and the network does not collapse all representations to zero vectors. *HINT: If you experience problems to achieve this goal, it might be helpful to tinker the learning rate.*\n",
    "\n",
    "* You are provided with a working example of triplet loss implementation for Keras below. You may directly use it.\n",
    "\n",
    "You may ignore the test set of Cifar-100 for this question as well. It suffices to use only the training set and split this, using the first 80 classes for training and the remaining 20 classes for one-shot testing.\n",
    "\n",
    "```python\n",
    "# Notice that ground truth variable is not used for loss calculation. It is used as a function argument to by-pass some Keras functionality. This is because the network structure already implies the ground truth for the anchor image with the \"positive\" image.\n",
    "import tensorflow as tf\n",
    "def triplet_loss(ground_truth, network_output):\n",
    "\n",
    "    anchor, positive, negative = tf.split(network_output, num_or_size_splits=3, axis=1)        \n",
    "    \n",
    "    for embedding in [anchor, positive, negative]:\n",
    "        embedding = tf.math.l2_normalize(embedding)\n",
    "\n",
    "    pos_dist = tf.reduce_sum(tf.square(tf.subtract(anchor, positive)), axis=1)\n",
    "    neg_dist = tf.reduce_sum(tf.square(tf.subtract(anchor, negative)), axis=1)\n",
    "    \n",
    "    margin = # define your margin\n",
    "    basic_loss = tf.add(tf.subtract(pos_dist, neg_dist), margin)\n",
    "    loss = tf.reduce_mean(tf.maximum(basic_loss, 0.0), axis=0)\n",
    "\n",
    "    return loss\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "derbigXY2uVG",
    "outputId": "f76eeddf-e29f-478b-cc07-97aa78ec0059"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
      "169009152/169001437 [==============================] - 13s 0us/step\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (_, _) = cifar100.load_data()\n",
    "\n",
    "input_size = (32, 32, 3)\n",
    "# embedding_dimensions = 128\n",
    "batch_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "P5ZBQZIhdXGw",
    "outputId": "11166962-6844-4c23-c903-bb88e0ea80e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Put the data in the following form: class, example, w, h, c\n",
      "Training set shape: (100, 500, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "#put the data in the following form: class, example, w, h, c\n",
    "print('Put the data in the following form: class, example, w, h, c')\n",
    "indexes = np.argsort(y_train.flatten())\n",
    "sorted_data = []\n",
    "for i in indexes:\n",
    "  sorted_data.append(x_train[i])\n",
    "x_train = np.array(sorted_data)\n",
    "y_train = np.array(sorted(y_train.flatten()))\n",
    "X=[]\n",
    "for i in range(100):\n",
    "  image_class = []\n",
    "  for j in range(500):\n",
    "    image_class.append(x_train[i*500+j])\n",
    "  X.append(np.array(image_class))\n",
    "X = np.array(X)\n",
    "print('Training set shape:',X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "TNdQsZG6DY84",
    "outputId": "242a51a6-2ead-41d1-8a94-d9b99b224ba8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split in training set and test in first 80 and later 20 categories, respectively\n",
      "Training set shape: (80, 500, 32, 32, 3)\n",
      "Test set shape: (20, 500, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "#split in training set and test\n",
    "print('Split in training set and test in first 80 and later 20 categories, '+\n",
    "      'respectively')\n",
    "X_test = X[-20:, :, :, :, :]\n",
    "X = X[:80, :, :, :, :]\n",
    "print('Training set shape:',X.shape)\n",
    "print('Test set shape:',X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rxHn2yT26TOA"
   },
   "outputs": [],
   "source": [
    "def get_batch(batch_size, X):\n",
    "    \"\"\"Create batch of n triplets anchor, positive, negative\"\"\"\n",
    "    n_classes, n_examples, w, h, d = X.shape\n",
    "    # randomly sample several classes to use in the batch\n",
    "    categories = np.random.choice(n_classes, size=(batch_size,), replace=False)\n",
    "    # initialize 3 empty arrays for the input image batch\n",
    "    triplet = [np.zeros((batch_size, h, w, 3)) for i in range(3)]\n",
    "    # initialize dummy vector fot labels (useless in triplenet)\n",
    "    targets = np.zeros((batch_size,))\n",
    "\n",
    "    for i in range(batch_size):\n",
    "      category = categories[i]\n",
    "      idx_1, idx_2 = random.sample(range(n_examples),k=2)\n",
    "      triplet[0][i, :, :, :] = X[category, idx_1].reshape(w, h, 3)\n",
    "      triplet[1][i, :, :, :] = X[category, idx_2].reshape(w, h, 3)\n",
    "      idx_3 = np.random.randint(0, n_examples)\n",
    "      category_2 = (category + np.random.randint(1,n_classes)) % n_classes\n",
    "      triplet[2][i, :, :, :] = X[category_2,idx_3].reshape(w, h, 3)\n",
    "    return triplet, targets\n",
    "\n",
    "def batch_generator(batch_size, X):\n",
    "    \"\"\"a generator for batches, so model.fit_generator can be used. \"\"\"\n",
    "    while True:\n",
    "      triplet, targets = get_batch(batch_size, X)\n",
    "      yield (triplet, targets)\n",
    "\n",
    "def train(model, X_train, batch_size=64, steps_per_epoch=625, epochs=1):\n",
    "    model.fit_generator(batch_generator(batch_size, X), \n",
    "                        steps_per_epoch=steps_per_epoch, epochs=epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "76I-WZOwPFL7"
   },
   "source": [
    "#test: the first 2 images should be in the same class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 253
    },
    "colab_type": "code",
    "id": "J6ODB5h9AREA",
    "outputId": "9d26adce-fc83-4127-b1ad-670671efb960"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 2, 32, 32, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQQAAADbCAYAAACLF+9EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nA1RF+QZczqJWAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 288x288 with 6 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "for b in batch_generator(2,X):\n",
    "  a = np.array(b[0], np.uint8)\n",
    "  print(a.shape)\n",
    "  image1 = a[0][0]\n",
    "  image2 = a[1][0]\n",
    "  image3 = a[2][0]\n",
    "  image4 = a[0][1]\n",
    "  image5 = a[1][1]\n",
    "  image6 = a[2][1]\n",
    "  fig=plt.figure(figsize=(4, 4))\n",
    "  for i in range(1,7):\n",
    "    fig.add_subplot(2, 3, i)\n",
    "    if i==1:\n",
    "      plt.imshow(image1)\n",
    "    elif i==2:\n",
    "      plt.imshow(image2)\n",
    "    elif i==3:\n",
    "      plt.imshow(image3)\n",
    "    elif i==4:\n",
    "      plt.imshow(image4)\n",
    "    elif i==5:\n",
    "      plt.imshow(image5)\n",
    "    elif i==6:\n",
    "      plt.imshow(image6)      \n",
    "  plt.show()\n",
    "  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5lJIU4yOutUT"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "def triplet_loss(ground_truth, network_output):\n",
    "#     anchor, positive, negative = (x for x in tf.split(network_output, num_or_size_splits=3, axis=1))\n",
    "#     pos_dist = tf.reduce_sum(tf.square(tf.subtract(anchor, positive)), axis=1)\n",
    "#     neg_dist = tf.reduce_sum(tf.square(tf.subtract(anchor, negative)), axis=1)\n",
    "    \n",
    "#     margin = 0.1\n",
    "#     basic_loss = tf.add(tf.subtract(pos_dist, neg_dist), margin)\n",
    "#     loss = tf.reduce_mean(tf.maximum(basic_loss, 0.0), axis=0)\n",
    "\n",
    "    total_lenght = 1536\n",
    "#     print('total_lenght=',  total_lenght)\n",
    "#     total_lenght =12\n",
    "    \n",
    "    anchor = network_output[:,0:int(total_lenght*1/3)]\n",
    "    positive = network_output[:,int(total_lenght*1/3):int(total_lenght*2/3)]\n",
    "    negative = network_output[:,int(total_lenght*2/3):int(total_lenght*3/3)]\n",
    "\n",
    "    # distance between the anchor and the positive\n",
    "    pos_dist = K.sum(K.square(anchor-positive),axis=1)\n",
    "\n",
    "    # distance between the anchor and the negative\n",
    "    neg_dist = K.sum(K.square(anchor-negative),axis=1)\n",
    "\n",
    "    # compute loss\n",
    "    basic_loss = K.mean(pos_dist-neg_dist+0.5)\n",
    "    loss = K.maximum(basic_loss,0.0)\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1198
    },
    "colab_type": "code",
    "id": "FIHD8l_rRLy5",
    "outputId": "ed377c68-dd81-467a-ef02-2047c2389184"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_7 (Conv2D)            (None, 32, 32, 64)        4864      \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)    (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 16, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 16, 16, 128)       512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)    (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 8, 8, 128)         147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)    (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 512)               1049088   \n",
      "=================================================================\n",
      "Total params: 1,276,672\n",
      "Trainable params: 1,276,032\n",
      "Non-trainable params: 640\n",
      "_________________________________________________________________\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "anchor (InputLayer)             (None, 32, 32, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "positive (InputLayer)           (None, 32, 32, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "negative (InputLayer)           (None, 32, 32, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_3 (Sequential)       (None, 512)          1276672     anchor[0][0]                     \n",
      "                                                                 positive[0][0]                   \n",
      "                                                                 negative[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_7 (Lambda)               (None, 512)          0           sequential_3[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lambda_8 (Lambda)               (None, 512)          0           sequential_3[2][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lambda_9 (Lambda)               (None, 512)          0           sequential_3[3][0]               \n",
      "__________________________________________________________________________________________________\n",
      "merged_layer (Concatenate)      (None, 1536)         0           lambda_7[0][0]                   \n",
      "                                                                 lambda_8[0][0]                   \n",
      "                                                                 lambda_9[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 1,276,672\n",
      "Trainable params: 1,276,032\n",
      "Non-trainable params: 640\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_shape = (32, 32, 3)\n",
    "anchor_input = Input(input_shape, name='anchor')\n",
    "positive_input = Input(input_shape, name='positive')\n",
    "negative_input = Input(input_shape, name='negative')\n",
    "\n",
    "# build convnet to use in each siamese 'leg'\n",
    "tripleNet = Sequential()\n",
    "\n",
    "tripleNet.add(Conv2D(64, (5,5), input_shape=input_shape, kernel_regularizer=l2(2e-4), padding='SAME'))\n",
    "tripleNet.add(BatchNormalization())\n",
    "tripleNet.add(LeakyReLU(alpha=0.1))\n",
    "tripleNet.add(MaxPooling2D())\n",
    "tripleNet.add(Dropout(0.25))\n",
    "\n",
    "tripleNet.add(Conv2D(128, (3,3), input_shape=input_shape, padding='SAME', kernel_regularizer=l2(2e-4)))\n",
    "tripleNet.add(BatchNormalization())\n",
    "tripleNet.add(LeakyReLU(alpha=0.1))\n",
    "tripleNet.add(MaxPooling2D())\n",
    "tripleNet.add(Dropout(0.25))\n",
    "\n",
    "tripleNet.add(Conv2D(128, (3,3), input_shape=input_shape, padding='SAME', kernel_regularizer=l2(2e-4)))\n",
    "tripleNet.add(BatchNormalization())\n",
    "tripleNet.add(LeakyReLU(alpha=0.1))\n",
    "tripleNet.add(MaxPooling2D())\n",
    "tripleNet.add(Dropout(0.25))\n",
    "\n",
    "tripleNet.add(Flatten())\n",
    "\n",
    "tripleNet.add(Dense(512, activation=\"sigmoid\", kernel_regularizer=l2(1e-3)))\n",
    "tripleNet.summary()\n",
    "\n",
    "encoded_anchor = tripleNet(anchor_input)\n",
    "encoded_positive = tripleNet(positive_input)\n",
    "encoded_negative = tripleNet(negative_input)\n",
    "\n",
    "layer1 = Lambda(lambda t: K.l2_normalize(t, axis=1))(encoded_anchor)\n",
    "layer2 = Lambda(lambda t: K.l2_normalize(t, axis=1))(encoded_positive)\n",
    "layer3 = Lambda(lambda t: K.l2_normalize(t, axis=1))(encoded_negative)\n",
    "\n",
    "\n",
    "merged_vector = concatenate([layer1, layer2, layer3], axis=-1, name='merged_layer')\n",
    "\n",
    "model = Model(inputs=[anchor_input,positive_input, negative_input], outputs=merged_vector)\n",
    "optimizer = optimizers.Adam(lr=0.0001)\n",
    "model.compile(loss=triplet_loss, optimizer=optimizer)\n",
    "model.summary()\n",
    "\n",
    "# # show model\n",
    "# from IPython.display import SVG\n",
    "# from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "# SVG(model_to_dot(model, show_shapes=True, show_layer_names=False, \n",
    "#                  rankdir='TB').create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 8839
    },
    "colab_type": "code",
    "id": "7w6o8xIXUADN",
    "outputId": "36101758-897b-43e5-da8e-eaf65e8a44cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Training loop 1 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 51s 81ms/step - loss: 0.0880\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 6.4% accuracy for 20-way one-shot learning\n",
      "********* New best one-shot accuracy, saving model ********\n",
      "=== Training loop 2 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 50s 80ms/step - loss: 0.0802\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 4.0% accuracy for 20-way one-shot learning\n",
      "=== Training loop 3 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 48s 76ms/step - loss: 0.0778\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 6.4% accuracy for 20-way one-shot learning\n",
      "********* New best one-shot accuracy, saving model ********\n",
      "=== Training loop 4 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 46s 74ms/step - loss: 0.0752\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 5.6% accuracy for 20-way one-shot learning\n",
      "=== Training loop 5 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 46s 74ms/step - loss: 0.0743\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 5.6% accuracy for 20-way one-shot learning\n",
      "=== Training loop 6 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 46s 74ms/step - loss: 0.0684\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 6.8% accuracy for 20-way one-shot learning\n",
      "********* New best one-shot accuracy, saving model ********\n",
      "=== Training loop 7 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 47s 75ms/step - loss: 0.0618\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 6.8% accuracy for 20-way one-shot learning\n",
      "********* New best one-shot accuracy, saving model ********\n",
      "=== Training loop 8 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 47s 75ms/step - loss: 0.0658\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 6.0% accuracy for 20-way one-shot learning\n",
      "=== Training loop 9 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 47s 74ms/step - loss: 0.0583\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 6.8% accuracy for 20-way one-shot learning\n",
      "********* New best one-shot accuracy, saving model ********\n",
      "=== Training loop 10 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 46s 74ms/step - loss: 0.0601\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 5.6% accuracy for 20-way one-shot learning\n",
      "=== Training loop 11 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 47s 75ms/step - loss: 0.0580\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 2.4% accuracy for 20-way one-shot learning\n",
      "=== Training loop 12 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 47s 75ms/step - loss: 0.0574\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 3.6% accuracy for 20-way one-shot learning\n",
      "=== Training loop 13 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 47s 75ms/step - loss: 0.0541\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 2.0% accuracy for 20-way one-shot learning\n",
      "=== Training loop 14 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 46s 74ms/step - loss: 0.0504\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 4.8% accuracy for 20-way one-shot learning\n",
      "=== Training loop 15 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 47s 75ms/step - loss: 0.0513\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 4.0% accuracy for 20-way one-shot learning\n",
      "=== Training loop 16 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 47s 75ms/step - loss: 0.0487\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 4.4% accuracy for 20-way one-shot learning\n",
      "=== Training loop 17 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 47s 75ms/step - loss: 0.0484\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 6.8% accuracy for 20-way one-shot learning\n",
      "********* New best one-shot accuracy, saving model ********\n",
      "=== Training loop 18 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 47s 75ms/step - loss: 0.0453\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 4.4% accuracy for 20-way one-shot learning\n",
      "=== Training loop 19 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 47s 75ms/step - loss: 0.0450\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 4.8% accuracy for 20-way one-shot learning\n",
      "=== Training loop 20 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 47s 75ms/step - loss: 0.0478\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 5.2% accuracy for 20-way one-shot learning\n",
      "=== Training loop 21 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 47s 74ms/step - loss: 0.0434\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 6.0% accuracy for 20-way one-shot learning\n",
      "=== Training loop 22 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 47s 75ms/step - loss: 0.0413\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 6.0% accuracy for 20-way one-shot learning\n",
      "=== Training loop 23 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 47s 75ms/step - loss: 0.0413\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 7.2% accuracy for 20-way one-shot learning\n",
      "********* New best one-shot accuracy, saving model ********\n",
      "=== Training loop 24 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 47s 75ms/step - loss: 0.0423\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 2.8% accuracy for 20-way one-shot learning\n",
      "=== Training loop 25 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 47s 75ms/step - loss: 0.0397\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 9.2% accuracy for 20-way one-shot learning\n",
      "********* New best one-shot accuracy, saving model ********\n",
      "=== Training loop 26 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 47s 75ms/step - loss: 0.0408\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 7.2% accuracy for 20-way one-shot learning\n",
      "=== Training loop 27 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 47s 75ms/step - loss: 0.0374\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 6.0% accuracy for 20-way one-shot learning\n",
      "=== Training loop 28 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 47s 75ms/step - loss: 0.0390\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 6.4% accuracy for 20-way one-shot learning\n",
      "=== Training loop 29 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 47s 75ms/step - loss: 0.0364\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 7.2% accuracy for 20-way one-shot learning\n",
      "=== Training loop 30 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 47s 75ms/step - loss: 0.0347\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 3.6% accuracy for 20-way one-shot learning\n",
      "=== Training loop 31 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 47s 75ms/step - loss: 0.0368\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 4.8% accuracy for 20-way one-shot learning\n",
      "=== Training loop 32 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 47s 74ms/step - loss: 0.0353\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 6.0% accuracy for 20-way one-shot learning\n",
      "=== Training loop 33 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 47s 75ms/step - loss: 0.0332\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 5.2% accuracy for 20-way one-shot learning\n",
      "=== Training loop 34 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 47s 75ms/step - loss: 0.0355\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 5.6% accuracy for 20-way one-shot learning\n",
      "=== Training loop 35 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 47s 75ms/step - loss: 0.0359\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 4.4% accuracy for 20-way one-shot learning\n",
      "=== Training loop 36 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 47s 75ms/step - loss: 0.0335\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 4.8% accuracy for 20-way one-shot learning\n",
      "=== Training loop 37 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 46s 74ms/step - loss: 0.0325\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 4.4% accuracy for 20-way one-shot learning\n",
      "=== Training loop 38 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 46s 74ms/step - loss: 0.0325\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 4.4% accuracy for 20-way one-shot learning\n",
      "=== Training loop 39 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 46s 74ms/step - loss: 0.0308\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 4.4% accuracy for 20-way one-shot learning\n",
      "=== Training loop 40 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 47s 75ms/step - loss: 0.0312\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 3.2% accuracy for 20-way one-shot learning\n",
      "=== Training loop 41 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 46s 74ms/step - loss: 0.0316\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 5.6% accuracy for 20-way one-shot learning\n",
      "=== Training loop 42 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 47s 75ms/step - loss: 0.0327\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 5.2% accuracy for 20-way one-shot learning\n",
      "=== Training loop 43 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 47s 75ms/step - loss: 0.0317\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 4.8% accuracy for 20-way one-shot learning\n",
      "=== Training loop 44 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 47s 75ms/step - loss: 0.0295\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 4.8% accuracy for 20-way one-shot learning\n",
      "=== Training loop 45 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 47s 75ms/step - loss: 0.0306\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 5.2% accuracy for 20-way one-shot learning\n",
      "=== Training loop 46 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 47s 75ms/step - loss: 0.0290\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 5.6% accuracy for 20-way one-shot learning\n",
      "=== Training loop 47 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 47s 75ms/step - loss: 0.0292\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 4.8% accuracy for 20-way one-shot learning\n",
      "=== Training loop 48 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 47s 75ms/step - loss: 0.0308\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 6.4% accuracy for 20-way one-shot learning\n",
      "=== Training loop 49 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 47s 75ms/step - loss: 0.0283\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 6.0% accuracy for 20-way one-shot learning\n",
      "=== Training loop 50 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 47s 75ms/step - loss: 0.0281\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 5.2% accuracy for 20-way one-shot learning\n",
      "=== Training loop 51 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 47s 75ms/step - loss: 0.0275\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 3.6% accuracy for 20-way one-shot learning\n",
      "=== Training loop 52 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 47s 75ms/step - loss: 0.0281\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 3.6% accuracy for 20-way one-shot learning\n",
      "=== Training loop 53 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 47s 75ms/step - loss: 0.0283\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 5.6% accuracy for 20-way one-shot learning\n",
      "=== Training loop 54 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 47s 75ms/step - loss: 0.0283\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 4.8% accuracy for 20-way one-shot learning\n",
      "=== Training loop 55 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 47s 75ms/step - loss: 0.0285\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 8.8% accuracy for 20-way one-shot learning\n",
      "=== Training loop 56 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 47s 75ms/step - loss: 0.0259\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 2.4% accuracy for 20-way one-shot learning\n",
      "=== Training loop 57 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 47s 75ms/step - loss: 0.0261\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 4.4% accuracy for 20-way one-shot learning\n",
      "=== Training loop 58 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 47s 75ms/step - loss: 0.0249\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 4.0% accuracy for 20-way one-shot learning\n",
      "=== Training loop 59 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 47s 75ms/step - loss: 0.0255\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 5.6% accuracy for 20-way one-shot learning\n",
      "=== Training loop 60 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 47s 75ms/step - loss: 0.0264\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 4.4% accuracy for 20-way one-shot learning\n",
      "=== Training loop 61 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 47s 75ms/step - loss: 0.0252\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 5.6% accuracy for 20-way one-shot learning\n",
      "=== Training loop 62 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 47s 75ms/step - loss: 0.0269\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 4.8% accuracy for 20-way one-shot learning\n",
      "=== Training loop 63 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 47s 75ms/step - loss: 0.0237\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 7.6% accuracy for 20-way one-shot learning\n",
      "=== Training loop 64 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 46s 74ms/step - loss: 0.0251\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 4.4% accuracy for 20-way one-shot learning\n",
      "=== Training loop 65 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 47s 75ms/step - loss: 0.0247\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 5.2% accuracy for 20-way one-shot learning\n",
      "=== Training loop 66 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 46s 74ms/step - loss: 0.0248\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 6.0% accuracy for 20-way one-shot learning\n",
      "=== Training loop 67 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 47s 75ms/step - loss: 0.0236\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 4.4% accuracy for 20-way one-shot learning\n",
      "=== Training loop 68 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 47s 75ms/step - loss: 0.0248\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 3.2% accuracy for 20-way one-shot learning\n",
      "=== Training loop 69 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 47s 75ms/step - loss: 0.0252\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 6.8% accuracy for 20-way one-shot learning\n",
      "=== Training loop 70 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 47s 75ms/step - loss: 0.0240\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 4.8% accuracy for 20-way one-shot learning\n",
      "=== Training loop 71 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 47s 75ms/step - loss: 0.0228\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 8.0% accuracy for 20-way one-shot learning\n",
      "=== Training loop 72 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 46s 74ms/step - loss: 0.0216\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 6.4% accuracy for 20-way one-shot learning\n",
      "=== Training loop 73 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 46s 74ms/step - loss: 0.0230\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 6.0% accuracy for 20-way one-shot learning\n",
      "=== Training loop 74 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 47s 75ms/step - loss: 0.0224\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 7.6% accuracy for 20-way one-shot learning\n",
      "=== Training loop 75 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 47s 75ms/step - loss: 0.0222\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 6.0% accuracy for 20-way one-shot learning\n",
      "=== Training loop 76 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 47s 75ms/step - loss: 0.0238\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 3.6% accuracy for 20-way one-shot learning\n",
      "=== Training loop 77 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 47s 75ms/step - loss: 0.0227\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 4.4% accuracy for 20-way one-shot learning\n",
      "=== Training loop 78 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 47s 75ms/step - loss: 0.0222\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 8.8% accuracy for 20-way one-shot learning\n",
      "=== Training loop 79 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 47s 75ms/step - loss: 0.0215\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 5.6% accuracy for 20-way one-shot learning\n",
      "=== Training loop 80 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 47s 75ms/step - loss: 0.0220\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 5.6% accuracy for 20-way one-shot learning\n",
      "=== Training loop 81 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 47s 75ms/step - loss: 0.0211\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 3.2% accuracy for 20-way one-shot learning\n",
      "=== Training loop 82 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 47s 75ms/step - loss: 0.0210\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 4.8% accuracy for 20-way one-shot learning\n",
      "=== Training loop 83 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 47s 75ms/step - loss: 0.0226\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 5.2% accuracy for 20-way one-shot learning\n",
      "=== Training loop 84 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 47s 74ms/step - loss: 0.0223\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 7.2% accuracy for 20-way one-shot learning\n",
      "=== Training loop 85 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 47s 75ms/step - loss: 0.0212\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 6.0% accuracy for 20-way one-shot learning\n",
      "=== Training loop 86 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 47s 75ms/step - loss: 0.0201\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 4.8% accuracy for 20-way one-shot learning\n",
      "=== Training loop 87 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 46s 74ms/step - loss: 0.0210\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 3.2% accuracy for 20-way one-shot learning\n",
      "=== Training loop 88 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 50s 80ms/step - loss: 0.0203\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 5.2% accuracy for 20-way one-shot learning\n",
      "=== Training loop 89 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 47s 76ms/step - loss: 0.0209\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 4.8% accuracy for 20-way one-shot learning\n",
      "=== Training loop 90 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 48s 76ms/step - loss: 0.0212\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 6.0% accuracy for 20-way one-shot learning\n",
      "=== Training loop 91 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 47s 76ms/step - loss: 0.0197\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 3.6% accuracy for 20-way one-shot learning\n",
      "=== Training loop 92 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 48s 76ms/step - loss: 0.0214\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 5.2% accuracy for 20-way one-shot learning\n",
      "=== Training loop 93 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 48s 76ms/step - loss: 0.0189\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 5.6% accuracy for 20-way one-shot learning\n",
      "=== Training loop 94 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 47s 76ms/step - loss: 0.0207\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 2.8% accuracy for 20-way one-shot learning\n",
      "=== Training loop 95 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 48s 76ms/step - loss: 0.0197\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 4.8% accuracy for 20-way one-shot learning\n",
      "=== Training loop 96 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 47s 76ms/step - loss: 0.0187\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 7.6% accuracy for 20-way one-shot learning\n",
      "=== Training loop 97 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 47s 76ms/step - loss: 0.0209\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 6.0% accuracy for 20-way one-shot learning\n",
      "=== Training loop 98 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 47s 76ms/step - loss: 0.0196\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 4.8% accuracy for 20-way one-shot learning\n",
      "=== Training loop 99 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 47s 76ms/step - loss: 0.0183\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 5.6% accuracy for 20-way one-shot learning\n",
      "=== Training loop 100 ===\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 48s 76ms/step - loss: 0.0200\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 5.2% accuracy for 20-way one-shot learning\n"
     ]
    }
   ],
   "source": [
    "loops = 100\n",
    "best_acc = 0\n",
    "for i in range(loops):\n",
    "    print(\"=== Training loop {} ===\".format(i+1))\n",
    "    train(model, X)\n",
    "    code_model = Model(inputs=model.get_layer(\"sequential_1\").get_input_at(1), outputs=model.get_layer(\"sequential_1\").get_output_at(1))\n",
    "    test_acc = test_oneshot(code_model, X_test)\n",
    "    if test_acc >= best_acc:\n",
    "        print(\"********* New best one-shot accuracy, saving model ********\")\n",
    "        code_model.save(os.path.join(\".\", \"code_model.h5\"))\n",
    "        best_acc = test_acc    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XHGJp45AR1qm"
   },
   "source": [
    "***\n",
    "\n",
    "### Task 2.2: One-shot learning with triplet neural codes\n",
    "**a)**\n",
    "* Use neural codes from the triplet network with L2-distance to evaluate one-shot learning accuracy for the remaining 20 classes of Cifar-100 with 250 random tasks. I.e. for a given one-shot task, obtain neural codes for the test image as well as the support set. Then pick the image from the support set that is closest (in L2-distance) to the test image as your one-shot prediction.\n",
    "* Explicitly state the accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6dStuzjVfW8O"
   },
   "source": [
    "For each epoch we run the test_oneshot function to get the accuracy. We then save the weights every time we get a better accuracy. The best result we got is 9.2%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "H9k08Wl9DBzs",
    "outputId": "0649c44d-5e32-4427-fe7d-b6a1a512aeb4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.2\n"
     ]
    }
   ],
   "source": [
    "print(best_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CCcmbz0UU7mR"
   },
   "source": [
    "***\n",
    "## Question 3: Performance comparison (3pt)\n",
    "\n",
    "\n",
    "**a)** What accuracy would random guessing achieve (on average) on this dataset? Motivate your answer briefly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BKGDydqsVVX1"
   },
   "source": [
    "Cifar-100 is a data set that consists of 100 possible classes to which one image can belong to. The well-known formula to obtain the accuracy of an item belongs to a class is $$ acc = \\frac{1}{n}\\% $$ where n is the total amount of classes. The evaluation of the first Siamese network required to be tested on 20 classes.\n",
    "\n",
    "We therefore generated 20 test pairs, one of which contains pictures of the same class, the other one pictures of different class. Randomly guessing which of the 20 contains the correct one has a chance of  $$ acc = \\frac{1}{20}\\% = 5\\% $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5KLXRv-eV04Q"
   },
   "source": [
    "**b)** Discuss and compare the performances of networks in tasks 1.1, 1.2 and 2.2. Briefly motivate and explain which task would be expected the highest accuracy. Explain the reasons of the accuracy difference if there are any. If there is almost no difference accuracy, explain the reason for that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "71kTHFBkcjp8"
   },
   "source": [
    "## Expected accuracy\n",
    "Taking into account the task of classifier embeddings using the Cifar100, it is expected that the performance among the three distinct networks will be different. Initially, the Siameses network will be expected to have a better accuracy compared to a CNN, due to the fact that in this case, we are dealing with 100 classes with fewer examples each, therefore the CNN will not be able to learn something meaningful from the data set, since we don't have enough data for each class. Moreover, the Siamense network has been built explicitly for learning an embedding, not for a classification task as in the case of the CNN\n",
    "\n",
    "On the other hand, the triplet network can be seen as an improvement of the Siameses network, because takes an anchor example and tries to bring positive examples closer while also pushing away negative examples. For that reason, the highest accuracy expected belongs to the Triplet Network.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-2EuoNTumptP"
   },
   "source": [
    " ## Obtained accuracy in 20-way one-shot learning\n",
    "\n",
    "*   Siameses Network: 26.4%\n",
    "*   Convolution Neural Network: 6.4%\n",
    "*   Triplet Network: 9.2%\n",
    "*   Random Guessing: 5%\n",
    "\n",
    "Explain the reasons of the accuracy difference if there are any: training epochs, steps per epoch, optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mA_Vi6ToeH35"
   },
   "source": [
    "In order to have a fair comparison between these models, we used the same embedding dimension (128).\n",
    "We tried several learning rates with different optimizers, and Adam seems to be the best one for our models. From the results, we can see that the Siamense works better than extracting codes from a CNN, and as explained before this was the predictable behavior. Although we expected better results with the Triplet network, we only got slightly better accuracy than random guessing. We tried several embeddings dimensions, a lot of different architectures and even different losses to improve this score, but nothing seemed really helpful. We presume then that (for this particular dataset), Siamense is the best model among the three.  It might be the case the for other datasets Triplet network is better than Siamense.\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Assignment_2.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
